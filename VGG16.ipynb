{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/cyizhuo/CUB-200-2011-dataset.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FineTuning VGG16 on CUB-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dir = '/content/CUB-200-2011-dataset/train'\n",
    "val_dir = '/content/CUB-200-2011-dataset/test'\n",
    "\n",
    "# Define transformations for data augmentation and normalization\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load the CUB dataset\n",
    "image_datasets = {x: datasets.ImageFolder(root=train_dir if x == 'train' else val_dir, transform=data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=2) for x in ['train', 'val']}\n",
    "\n",
    "# Load pre-trained VGG16\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "# Freeze all layers\n",
    "for param in vgg16.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze some convolutional layers\n",
    "for i, param in enumerate(vgg16.features.parameters(), 1):\n",
    "    if i > 15:  # Adjust the number of layers to unfreeze as needed\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Modify the classifier\n",
    "num_features = vgg16.classifier[6].in_features\n",
    "vgg16.classifier[6] = nn.Linear(num_features, 200)  # Set to 200 for CUB dataset\n",
    "\n",
    "\n",
    "# Move model to device\n",
    "vgg16 = vgg16.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 25\n",
    "for epoch in range(num_epochs):\n",
    "    vgg16.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for images, labels in dataloaders['train']:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = vgg16(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloaders['train'].dataset)\n",
    "    train_accuracy = correct_train / total_train\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Train Accuracy: {train_accuracy:.2%}\")\n",
    "\n",
    "    # Evaluation loop\n",
    "    vgg16.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    val_running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloaders['val']:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = vgg16(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            val_running_loss += val_loss.item() * images.size(0)\n",
    "\n",
    "    val_epoch_loss = val_running_loss / len(dataloaders['val'].dataset)\n",
    "    val_accuracy = correct_val / total_val\n",
    "\n",
    "    print(f\"Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.2%}\")\n",
    "\n",
    "# Print final test accuracy\n",
    "print(f\"Final Test Accuracy: {val_accuracy:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
