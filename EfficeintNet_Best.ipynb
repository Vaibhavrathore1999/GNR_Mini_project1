{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/cyizhuo/CUB-200-2011-dataset.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICTycvara-6b",
        "outputId": "7bcb29a1-b5b9-4d5f-e703-b46001c9540a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CUB-200-2011-dataset'...\n",
            "remote: Enumerating objects: 12221, done.\u001b[K\n",
            "remote: Total 12221 (delta 0), reused 0 (delta 0), pack-reused 12221\u001b[K\n",
            "Receiving objects: 100% (12221/12221), 1.05 GiB | 26.43 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n",
            "Updating files: 100% (11789/11789), done.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the pre-trained Inception-ResNet V2 model without the top layers\n",
        "model = tf.keras.applications.InceptionResNetV2(include_top=False, weights='imagenet')\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0F06_aZaojG",
        "outputId": "b4ce9f99-d02f-42c4-91cf-96824cd16647"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"inception_resnet_v2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, None, None, 3)]      0         []                            \n",
            "                                                                                                  \n",
            " conv2d_203 (Conv2D)         (None, None, None, 32)       864       ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_203 (B  (None, None, None, 32)       96        ['conv2d_203[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_203 (Activation  (None, None, None, 32)       0         ['batch_normalization_203[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_204 (Conv2D)         (None, None, None, 32)       9216      ['activation_203[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_204 (B  (None, None, None, 32)       96        ['conv2d_204[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_204 (Activation  (None, None, None, 32)       0         ['batch_normalization_204[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_205 (Conv2D)         (None, None, None, 64)       18432     ['activation_204[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_205 (B  (None, None, None, 64)       192       ['conv2d_205[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_205 (Activation  (None, None, None, 64)       0         ['batch_normalization_205[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPoolin  (None, None, None, 64)       0         ['activation_205[0][0]']      \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_206 (Conv2D)         (None, None, None, 80)       5120      ['max_pooling2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_206 (B  (None, None, None, 80)       240       ['conv2d_206[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_206 (Activation  (None, None, None, 80)       0         ['batch_normalization_206[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_207 (Conv2D)         (None, None, None, 192)      138240    ['activation_206[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_207 (B  (None, None, None, 192)      576       ['conv2d_207[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_207 (Activation  (None, None, None, 192)      0         ['batch_normalization_207[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPoolin  (None, None, None, 192)      0         ['activation_207[0][0]']      \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_211 (Conv2D)         (None, None, None, 64)       12288     ['max_pooling2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_211 (B  (None, None, None, 64)       192       ['conv2d_211[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_211 (Activation  (None, None, None, 64)       0         ['batch_normalization_211[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_209 (Conv2D)         (None, None, None, 48)       9216      ['max_pooling2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_212 (Conv2D)         (None, None, None, 96)       55296     ['activation_211[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_209 (B  (None, None, None, 48)       144       ['conv2d_209[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_212 (B  (None, None, None, 96)       288       ['conv2d_212[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_209 (Activation  (None, None, None, 48)       0         ['batch_normalization_209[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_212 (Activation  (None, None, None, 96)       0         ['batch_normalization_212[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (Avera  (None, None, None, 192)      0         ['max_pooling2d_5[0][0]']     \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_208 (Conv2D)         (None, None, None, 96)       18432     ['max_pooling2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_210 (Conv2D)         (None, None, None, 64)       76800     ['activation_209[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_213 (Conv2D)         (None, None, None, 96)       82944     ['activation_212[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_214 (Conv2D)         (None, None, None, 64)       12288     ['average_pooling2d_1[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_208 (B  (None, None, None, 96)       288       ['conv2d_208[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_210 (B  (None, None, None, 64)       192       ['conv2d_210[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_213 (B  (None, None, None, 96)       288       ['conv2d_213[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_214 (B  (None, None, None, 64)       192       ['conv2d_214[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_208 (Activation  (None, None, None, 96)       0         ['batch_normalization_208[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_210 (Activation  (None, None, None, 64)       0         ['batch_normalization_210[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_213 (Activation  (None, None, None, 96)       0         ['batch_normalization_213[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_214 (Activation  (None, None, None, 64)       0         ['batch_normalization_214[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed_5b (Concatenate)      (None, None, None, 320)      0         ['activation_208[0][0]',      \n",
            "                                                                     'activation_210[0][0]',      \n",
            "                                                                     'activation_213[0][0]',      \n",
            "                                                                     'activation_214[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_218 (Conv2D)         (None, None, None, 32)       10240     ['mixed_5b[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_218 (B  (None, None, None, 32)       96        ['conv2d_218[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_218 (Activation  (None, None, None, 32)       0         ['batch_normalization_218[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_216 (Conv2D)         (None, None, None, 32)       10240     ['mixed_5b[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_219 (Conv2D)         (None, None, None, 48)       13824     ['activation_218[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_216 (B  (None, None, None, 32)       96        ['conv2d_216[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_219 (B  (None, None, None, 48)       144       ['conv2d_219[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_216 (Activation  (None, None, None, 32)       0         ['batch_normalization_216[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_219 (Activation  (None, None, None, 48)       0         ['batch_normalization_219[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_215 (Conv2D)         (None, None, None, 32)       10240     ['mixed_5b[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_217 (Conv2D)         (None, None, None, 32)       9216      ['activation_216[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_220 (Conv2D)         (None, None, None, 64)       27648     ['activation_219[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_215 (B  (None, None, None, 32)       96        ['conv2d_215[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_217 (B  (None, None, None, 32)       96        ['conv2d_217[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_220 (B  (None, None, None, 64)       192       ['conv2d_220[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_215 (Activation  (None, None, None, 32)       0         ['batch_normalization_215[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_217 (Activation  (None, None, None, 32)       0         ['batch_normalization_217[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_220 (Activation  (None, None, None, 64)       0         ['batch_normalization_220[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block35_1_mixed (Concatena  (None, None, None, 128)      0         ['activation_215[0][0]',      \n",
            " te)                                                                 'activation_217[0][0]',      \n",
            "                                                                     'activation_220[0][0]']      \n",
            "                                                                                                  \n",
            " block35_1_conv (Conv2D)     (None, None, None, 320)      41280     ['block35_1_mixed[0][0]']     \n",
            "                                                                                                  \n",
            " custom_scale_layer_40 (Cus  (None, None, None, 320)      0         ['mixed_5b[0][0]',            \n",
            " tomScaleLayer)                                                      'block35_1_conv[0][0]']      \n",
            "                                                                                                  \n",
            " block35_1_ac (Activation)   (None, None, None, 320)      0         ['custom_scale_layer_40[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_224 (Conv2D)         (None, None, None, 32)       10240     ['block35_1_ac[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_224 (B  (None, None, None, 32)       96        ['conv2d_224[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_224 (Activation  (None, None, None, 32)       0         ['batch_normalization_224[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_222 (Conv2D)         (None, None, None, 32)       10240     ['block35_1_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_225 (Conv2D)         (None, None, None, 48)       13824     ['activation_224[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_222 (B  (None, None, None, 32)       96        ['conv2d_222[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_225 (B  (None, None, None, 48)       144       ['conv2d_225[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_222 (Activation  (None, None, None, 32)       0         ['batch_normalization_222[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_225 (Activation  (None, None, None, 48)       0         ['batch_normalization_225[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_221 (Conv2D)         (None, None, None, 32)       10240     ['block35_1_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_223 (Conv2D)         (None, None, None, 32)       9216      ['activation_222[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_226 (Conv2D)         (None, None, None, 64)       27648     ['activation_225[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_221 (B  (None, None, None, 32)       96        ['conv2d_221[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_223 (B  (None, None, None, 32)       96        ['conv2d_223[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_226 (B  (None, None, None, 64)       192       ['conv2d_226[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_221 (Activation  (None, None, None, 32)       0         ['batch_normalization_221[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_223 (Activation  (None, None, None, 32)       0         ['batch_normalization_223[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_226 (Activation  (None, None, None, 64)       0         ['batch_normalization_226[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block35_2_mixed (Concatena  (None, None, None, 128)      0         ['activation_221[0][0]',      \n",
            " te)                                                                 'activation_223[0][0]',      \n",
            "                                                                     'activation_226[0][0]']      \n",
            "                                                                                                  \n",
            " block35_2_conv (Conv2D)     (None, None, None, 320)      41280     ['block35_2_mixed[0][0]']     \n",
            "                                                                                                  \n",
            " custom_scale_layer_41 (Cus  (None, None, None, 320)      0         ['block35_1_ac[0][0]',        \n",
            " tomScaleLayer)                                                      'block35_2_conv[0][0]']      \n",
            "                                                                                                  \n",
            " block35_2_ac (Activation)   (None, None, None, 320)      0         ['custom_scale_layer_41[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_230 (Conv2D)         (None, None, None, 32)       10240     ['block35_2_ac[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_230 (B  (None, None, None, 32)       96        ['conv2d_230[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_230 (Activation  (None, None, None, 32)       0         ['batch_normalization_230[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_228 (Conv2D)         (None, None, None, 32)       10240     ['block35_2_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_231 (Conv2D)         (None, None, None, 48)       13824     ['activation_230[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_228 (B  (None, None, None, 32)       96        ['conv2d_228[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_231 (B  (None, None, None, 48)       144       ['conv2d_231[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_228 (Activation  (None, None, None, 32)       0         ['batch_normalization_228[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_231 (Activation  (None, None, None, 48)       0         ['batch_normalization_231[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_227 (Conv2D)         (None, None, None, 32)       10240     ['block35_2_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_229 (Conv2D)         (None, None, None, 32)       9216      ['activation_228[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_232 (Conv2D)         (None, None, None, 64)       27648     ['activation_231[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_227 (B  (None, None, None, 32)       96        ['conv2d_227[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_229 (B  (None, None, None, 32)       96        ['conv2d_229[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_232 (B  (None, None, None, 64)       192       ['conv2d_232[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_227 (Activation  (None, None, None, 32)       0         ['batch_normalization_227[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_229 (Activation  (None, None, None, 32)       0         ['batch_normalization_229[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_232 (Activation  (None, None, None, 64)       0         ['batch_normalization_232[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block35_3_mixed (Concatena  (None, None, None, 128)      0         ['activation_227[0][0]',      \n",
            " te)                                                                 'activation_229[0][0]',      \n",
            "                                                                     'activation_232[0][0]']      \n",
            "                                                                                                  \n",
            " block35_3_conv (Conv2D)     (None, None, None, 320)      41280     ['block35_3_mixed[0][0]']     \n",
            "                                                                                                  \n",
            " custom_scale_layer_42 (Cus  (None, None, None, 320)      0         ['block35_2_ac[0][0]',        \n",
            " tomScaleLayer)                                                      'block35_3_conv[0][0]']      \n",
            "                                                                                                  \n",
            " block35_3_ac (Activation)   (None, None, None, 320)      0         ['custom_scale_layer_42[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_236 (Conv2D)         (None, None, None, 32)       10240     ['block35_3_ac[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_236 (B  (None, None, None, 32)       96        ['conv2d_236[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_236 (Activation  (None, None, None, 32)       0         ['batch_normalization_236[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_234 (Conv2D)         (None, None, None, 32)       10240     ['block35_3_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_237 (Conv2D)         (None, None, None, 48)       13824     ['activation_236[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_234 (B  (None, None, None, 32)       96        ['conv2d_234[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_237 (B  (None, None, None, 48)       144       ['conv2d_237[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_234 (Activation  (None, None, None, 32)       0         ['batch_normalization_234[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_237 (Activation  (None, None, None, 48)       0         ['batch_normalization_237[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_233 (Conv2D)         (None, None, None, 32)       10240     ['block35_3_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_235 (Conv2D)         (None, None, None, 32)       9216      ['activation_234[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_238 (Conv2D)         (None, None, None, 64)       27648     ['activation_237[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_233 (B  (None, None, None, 32)       96        ['conv2d_233[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_235 (B  (None, None, None, 32)       96        ['conv2d_235[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_238 (B  (None, None, None, 64)       192       ['conv2d_238[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_233 (Activation  (None, None, None, 32)       0         ['batch_normalization_233[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_235 (Activation  (None, None, None, 32)       0         ['batch_normalization_235[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_238 (Activation  (None, None, None, 64)       0         ['batch_normalization_238[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block35_4_mixed (Concatena  (None, None, None, 128)      0         ['activation_233[0][0]',      \n",
            " te)                                                                 'activation_235[0][0]',      \n",
            "                                                                     'activation_238[0][0]']      \n",
            "                                                                                                  \n",
            " block35_4_conv (Conv2D)     (None, None, None, 320)      41280     ['block35_4_mixed[0][0]']     \n",
            "                                                                                                  \n",
            " custom_scale_layer_43 (Cus  (None, None, None, 320)      0         ['block35_3_ac[0][0]',        \n",
            " tomScaleLayer)                                                      'block35_4_conv[0][0]']      \n",
            "                                                                                                  \n",
            " block35_4_ac (Activation)   (None, None, None, 320)      0         ['custom_scale_layer_43[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_242 (Conv2D)         (None, None, None, 32)       10240     ['block35_4_ac[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_242 (B  (None, None, None, 32)       96        ['conv2d_242[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_242 (Activation  (None, None, None, 32)       0         ['batch_normalization_242[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_240 (Conv2D)         (None, None, None, 32)       10240     ['block35_4_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_243 (Conv2D)         (None, None, None, 48)       13824     ['activation_242[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_240 (B  (None, None, None, 32)       96        ['conv2d_240[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_243 (B  (None, None, None, 48)       144       ['conv2d_243[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_240 (Activation  (None, None, None, 32)       0         ['batch_normalization_240[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_243 (Activation  (None, None, None, 48)       0         ['batch_normalization_243[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_239 (Conv2D)         (None, None, None, 32)       10240     ['block35_4_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_241 (Conv2D)         (None, None, None, 32)       9216      ['activation_240[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_244 (Conv2D)         (None, None, None, 64)       27648     ['activation_243[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_239 (B  (None, None, None, 32)       96        ['conv2d_239[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_241 (B  (None, None, None, 32)       96        ['conv2d_241[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_244 (B  (None, None, None, 64)       192       ['conv2d_244[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_239 (Activation  (None, None, None, 32)       0         ['batch_normalization_239[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_241 (Activation  (None, None, None, 32)       0         ['batch_normalization_241[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_244 (Activation  (None, None, None, 64)       0         ['batch_normalization_244[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block35_5_mixed (Concatena  (None, None, None, 128)      0         ['activation_239[0][0]',      \n",
            " te)                                                                 'activation_241[0][0]',      \n",
            "                                                                     'activation_244[0][0]']      \n",
            "                                                                                                  \n",
            " block35_5_conv (Conv2D)     (None, None, None, 320)      41280     ['block35_5_mixed[0][0]']     \n",
            "                                                                                                  \n",
            " custom_scale_layer_44 (Cus  (None, None, None, 320)      0         ['block35_4_ac[0][0]',        \n",
            " tomScaleLayer)                                                      'block35_5_conv[0][0]']      \n",
            "                                                                                                  \n",
            " block35_5_ac (Activation)   (None, None, None, 320)      0         ['custom_scale_layer_44[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_248 (Conv2D)         (None, None, None, 32)       10240     ['block35_5_ac[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_248 (B  (None, None, None, 32)       96        ['conv2d_248[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_248 (Activation  (None, None, None, 32)       0         ['batch_normalization_248[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_246 (Conv2D)         (None, None, None, 32)       10240     ['block35_5_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_249 (Conv2D)         (None, None, None, 48)       13824     ['activation_248[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_246 (B  (None, None, None, 32)       96        ['conv2d_246[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_249 (B  (None, None, None, 48)       144       ['conv2d_249[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_246 (Activation  (None, None, None, 32)       0         ['batch_normalization_246[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_249 (Activation  (None, None, None, 48)       0         ['batch_normalization_249[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_245 (Conv2D)         (None, None, None, 32)       10240     ['block35_5_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_247 (Conv2D)         (None, None, None, 32)       9216      ['activation_246[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_250 (Conv2D)         (None, None, None, 64)       27648     ['activation_249[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_245 (B  (None, None, None, 32)       96        ['conv2d_245[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_247 (B  (None, None, None, 32)       96        ['conv2d_247[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_250 (B  (None, None, None, 64)       192       ['conv2d_250[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_245 (Activation  (None, None, None, 32)       0         ['batch_normalization_245[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_247 (Activation  (None, None, None, 32)       0         ['batch_normalization_247[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_250 (Activation  (None, None, None, 64)       0         ['batch_normalization_250[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block35_6_mixed (Concatena  (None, None, None, 128)      0         ['activation_245[0][0]',      \n",
            " te)                                                                 'activation_247[0][0]',      \n",
            "                                                                     'activation_250[0][0]']      \n",
            "                                                                                                  \n",
            " block35_6_conv (Conv2D)     (None, None, None, 320)      41280     ['block35_6_mixed[0][0]']     \n",
            "                                                                                                  \n",
            " custom_scale_layer_45 (Cus  (None, None, None, 320)      0         ['block35_5_ac[0][0]',        \n",
            " tomScaleLayer)                                                      'block35_6_conv[0][0]']      \n",
            "                                                                                                  \n",
            " block35_6_ac (Activation)   (None, None, None, 320)      0         ['custom_scale_layer_45[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_254 (Conv2D)         (None, None, None, 32)       10240     ['block35_6_ac[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_254 (B  (None, None, None, 32)       96        ['conv2d_254[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_254 (Activation  (None, None, None, 32)       0         ['batch_normalization_254[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_252 (Conv2D)         (None, None, None, 32)       10240     ['block35_6_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_255 (Conv2D)         (None, None, None, 48)       13824     ['activation_254[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_252 (B  (None, None, None, 32)       96        ['conv2d_252[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_255 (B  (None, None, None, 48)       144       ['conv2d_255[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_252 (Activation  (None, None, None, 32)       0         ['batch_normalization_252[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_255 (Activation  (None, None, None, 48)       0         ['batch_normalization_255[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_251 (Conv2D)         (None, None, None, 32)       10240     ['block35_6_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_253 (Conv2D)         (None, None, None, 32)       9216      ['activation_252[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_256 (Conv2D)         (None, None, None, 64)       27648     ['activation_255[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_251 (B  (None, None, None, 32)       96        ['conv2d_251[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_253 (B  (None, None, None, 32)       96        ['conv2d_253[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_256 (B  (None, None, None, 64)       192       ['conv2d_256[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_251 (Activation  (None, None, None, 32)       0         ['batch_normalization_251[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_253 (Activation  (None, None, None, 32)       0         ['batch_normalization_253[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_256 (Activation  (None, None, None, 64)       0         ['batch_normalization_256[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block35_7_mixed (Concatena  (None, None, None, 128)      0         ['activation_251[0][0]',      \n",
            " te)                                                                 'activation_253[0][0]',      \n",
            "                                                                     'activation_256[0][0]']      \n",
            "                                                                                                  \n",
            " block35_7_conv (Conv2D)     (None, None, None, 320)      41280     ['block35_7_mixed[0][0]']     \n",
            "                                                                                                  \n",
            " custom_scale_layer_46 (Cus  (None, None, None, 320)      0         ['block35_6_ac[0][0]',        \n",
            " tomScaleLayer)                                                      'block35_7_conv[0][0]']      \n",
            "                                                                                                  \n",
            " block35_7_ac (Activation)   (None, None, None, 320)      0         ['custom_scale_layer_46[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_260 (Conv2D)         (None, None, None, 32)       10240     ['block35_7_ac[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_260 (B  (None, None, None, 32)       96        ['conv2d_260[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_260 (Activation  (None, None, None, 32)       0         ['batch_normalization_260[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_258 (Conv2D)         (None, None, None, 32)       10240     ['block35_7_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_261 (Conv2D)         (None, None, None, 48)       13824     ['activation_260[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_258 (B  (None, None, None, 32)       96        ['conv2d_258[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_261 (B  (None, None, None, 48)       144       ['conv2d_261[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_258 (Activation  (None, None, None, 32)       0         ['batch_normalization_258[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_261 (Activation  (None, None, None, 48)       0         ['batch_normalization_261[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_257 (Conv2D)         (None, None, None, 32)       10240     ['block35_7_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_259 (Conv2D)         (None, None, None, 32)       9216      ['activation_258[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_262 (Conv2D)         (None, None, None, 64)       27648     ['activation_261[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_257 (B  (None, None, None, 32)       96        ['conv2d_257[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_259 (B  (None, None, None, 32)       96        ['conv2d_259[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_262 (B  (None, None, None, 64)       192       ['conv2d_262[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_257 (Activation  (None, None, None, 32)       0         ['batch_normalization_257[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_259 (Activation  (None, None, None, 32)       0         ['batch_normalization_259[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_262 (Activation  (None, None, None, 64)       0         ['batch_normalization_262[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block35_8_mixed (Concatena  (None, None, None, 128)      0         ['activation_257[0][0]',      \n",
            " te)                                                                 'activation_259[0][0]',      \n",
            "                                                                     'activation_262[0][0]']      \n",
            "                                                                                                  \n",
            " block35_8_conv (Conv2D)     (None, None, None, 320)      41280     ['block35_8_mixed[0][0]']     \n",
            "                                                                                                  \n",
            " custom_scale_layer_47 (Cus  (None, None, None, 320)      0         ['block35_7_ac[0][0]',        \n",
            " tomScaleLayer)                                                      'block35_8_conv[0][0]']      \n",
            "                                                                                                  \n",
            " block35_8_ac (Activation)   (None, None, None, 320)      0         ['custom_scale_layer_47[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_266 (Conv2D)         (None, None, None, 32)       10240     ['block35_8_ac[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_266 (B  (None, None, None, 32)       96        ['conv2d_266[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_266 (Activation  (None, None, None, 32)       0         ['batch_normalization_266[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_264 (Conv2D)         (None, None, None, 32)       10240     ['block35_8_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_267 (Conv2D)         (None, None, None, 48)       13824     ['activation_266[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_264 (B  (None, None, None, 32)       96        ['conv2d_264[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_267 (B  (None, None, None, 48)       144       ['conv2d_267[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_264 (Activation  (None, None, None, 32)       0         ['batch_normalization_264[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_267 (Activation  (None, None, None, 48)       0         ['batch_normalization_267[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_263 (Conv2D)         (None, None, None, 32)       10240     ['block35_8_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_265 (Conv2D)         (None, None, None, 32)       9216      ['activation_264[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_268 (Conv2D)         (None, None, None, 64)       27648     ['activation_267[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_263 (B  (None, None, None, 32)       96        ['conv2d_263[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_265 (B  (None, None, None, 32)       96        ['conv2d_265[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_268 (B  (None, None, None, 64)       192       ['conv2d_268[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_263 (Activation  (None, None, None, 32)       0         ['batch_normalization_263[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_265 (Activation  (None, None, None, 32)       0         ['batch_normalization_265[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_268 (Activation  (None, None, None, 64)       0         ['batch_normalization_268[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block35_9_mixed (Concatena  (None, None, None, 128)      0         ['activation_263[0][0]',      \n",
            " te)                                                                 'activation_265[0][0]',      \n",
            "                                                                     'activation_268[0][0]']      \n",
            "                                                                                                  \n",
            " block35_9_conv (Conv2D)     (None, None, None, 320)      41280     ['block35_9_mixed[0][0]']     \n",
            "                                                                                                  \n",
            " custom_scale_layer_48 (Cus  (None, None, None, 320)      0         ['block35_8_ac[0][0]',        \n",
            " tomScaleLayer)                                                      'block35_9_conv[0][0]']      \n",
            "                                                                                                  \n",
            " block35_9_ac (Activation)   (None, None, None, 320)      0         ['custom_scale_layer_48[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_272 (Conv2D)         (None, None, None, 32)       10240     ['block35_9_ac[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_272 (B  (None, None, None, 32)       96        ['conv2d_272[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_272 (Activation  (None, None, None, 32)       0         ['batch_normalization_272[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_270 (Conv2D)         (None, None, None, 32)       10240     ['block35_9_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_273 (Conv2D)         (None, None, None, 48)       13824     ['activation_272[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_270 (B  (None, None, None, 32)       96        ['conv2d_270[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_273 (B  (None, None, None, 48)       144       ['conv2d_273[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_270 (Activation  (None, None, None, 32)       0         ['batch_normalization_270[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_273 (Activation  (None, None, None, 48)       0         ['batch_normalization_273[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_269 (Conv2D)         (None, None, None, 32)       10240     ['block35_9_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_271 (Conv2D)         (None, None, None, 32)       9216      ['activation_270[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_274 (Conv2D)         (None, None, None, 64)       27648     ['activation_273[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_269 (B  (None, None, None, 32)       96        ['conv2d_269[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_271 (B  (None, None, None, 32)       96        ['conv2d_271[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_274 (B  (None, None, None, 64)       192       ['conv2d_274[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_269 (Activation  (None, None, None, 32)       0         ['batch_normalization_269[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_271 (Activation  (None, None, None, 32)       0         ['batch_normalization_271[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_274 (Activation  (None, None, None, 64)       0         ['batch_normalization_274[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block35_10_mixed (Concaten  (None, None, None, 128)      0         ['activation_269[0][0]',      \n",
            " ate)                                                                'activation_271[0][0]',      \n",
            "                                                                     'activation_274[0][0]']      \n",
            "                                                                                                  \n",
            " block35_10_conv (Conv2D)    (None, None, None, 320)      41280     ['block35_10_mixed[0][0]']    \n",
            "                                                                                                  \n",
            " custom_scale_layer_49 (Cus  (None, None, None, 320)      0         ['block35_9_ac[0][0]',        \n",
            " tomScaleLayer)                                                      'block35_10_conv[0][0]']     \n",
            "                                                                                                  \n",
            " block35_10_ac (Activation)  (None, None, None, 320)      0         ['custom_scale_layer_49[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_276 (Conv2D)         (None, None, None, 256)      81920     ['block35_10_ac[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_276 (B  (None, None, None, 256)      768       ['conv2d_276[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_276 (Activation  (None, None, None, 256)      0         ['batch_normalization_276[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_277 (Conv2D)         (None, None, None, 256)      589824    ['activation_276[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_277 (B  (None, None, None, 256)      768       ['conv2d_277[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_277 (Activation  (None, None, None, 256)      0         ['batch_normalization_277[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_275 (Conv2D)         (None, None, None, 384)      1105920   ['block35_10_ac[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_278 (Conv2D)         (None, None, None, 384)      884736    ['activation_277[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_275 (B  (None, None, None, 384)      1152      ['conv2d_275[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_278 (B  (None, None, None, 384)      1152      ['conv2d_278[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_275 (Activation  (None, None, None, 384)      0         ['batch_normalization_275[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_278 (Activation  (None, None, None, 384)      0         ['batch_normalization_278[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPoolin  (None, None, None, 320)      0         ['block35_10_ac[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " mixed_6a (Concatenate)      (None, None, None, 1088)     0         ['activation_275[0][0]',      \n",
            "                                                                     'activation_278[0][0]',      \n",
            "                                                                     'max_pooling2d_6[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_280 (Conv2D)         (None, None, None, 128)      139264    ['mixed_6a[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_280 (B  (None, None, None, 128)      384       ['conv2d_280[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_280 (Activation  (None, None, None, 128)      0         ['batch_normalization_280[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_281 (Conv2D)         (None, None, None, 160)      143360    ['activation_280[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_281 (B  (None, None, None, 160)      480       ['conv2d_281[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_281 (Activation  (None, None, None, 160)      0         ['batch_normalization_281[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_279 (Conv2D)         (None, None, None, 192)      208896    ['mixed_6a[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_282 (Conv2D)         (None, None, None, 192)      215040    ['activation_281[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_279 (B  (None, None, None, 192)      576       ['conv2d_279[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_282 (B  (None, None, None, 192)      576       ['conv2d_282[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_279 (Activation  (None, None, None, 192)      0         ['batch_normalization_279[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_282 (Activation  (None, None, None, 192)      0         ['batch_normalization_282[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block17_1_mixed (Concatena  (None, None, None, 384)      0         ['activation_279[0][0]',      \n",
            " te)                                                                 'activation_282[0][0]']      \n",
            "                                                                                                  \n",
            " block17_1_conv (Conv2D)     (None, None, None, 1088)     418880    ['block17_1_mixed[0][0]']     \n",
            "                                                                                                  \n",
            " custom_scale_layer_50 (Cus  (None, None, None, 1088)     0         ['mixed_6a[0][0]',            \n",
            " tomScaleLayer)                                                      'block17_1_conv[0][0]']      \n",
            "                                                                                                  \n",
            " block17_1_ac (Activation)   (None, None, None, 1088)     0         ['custom_scale_layer_50[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_284 (Conv2D)         (None, None, None, 128)      139264    ['block17_1_ac[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_284 (B  (None, None, None, 128)      384       ['conv2d_284[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_284 (Activation  (None, None, None, 128)      0         ['batch_normalization_284[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_285 (Conv2D)         (None, None, None, 160)      143360    ['activation_284[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_285 (B  (None, None, None, 160)      480       ['conv2d_285[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_285 (Activation  (None, None, None, 160)      0         ['batch_normalization_285[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_283 (Conv2D)         (None, None, None, 192)      208896    ['block17_1_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_286 (Conv2D)         (None, None, None, 192)      215040    ['activation_285[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_283 (B  (None, None, None, 192)      576       ['conv2d_283[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_286 (B  (None, None, None, 192)      576       ['conv2d_286[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_283 (Activation  (None, None, None, 192)      0         ['batch_normalization_283[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_286 (Activation  (None, None, None, 192)      0         ['batch_normalization_286[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block17_2_mixed (Concatena  (None, None, None, 384)      0         ['activation_283[0][0]',      \n",
            " te)                                                                 'activation_286[0][0]']      \n",
            "                                                                                                  \n",
            " block17_2_conv (Conv2D)     (None, None, None, 1088)     418880    ['block17_2_mixed[0][0]']     \n",
            "                                                                                                  \n",
            " custom_scale_layer_51 (Cus  (None, None, None, 1088)     0         ['block17_1_ac[0][0]',        \n",
            " tomScaleLayer)                                                      'block17_2_conv[0][0]']      \n",
            "                                                                                                  \n",
            " block17_2_ac (Activation)   (None, None, None, 1088)     0         ['custom_scale_layer_51[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_288 (Conv2D)         (None, None, None, 128)      139264    ['block17_2_ac[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_288 (B  (None, None, None, 128)      384       ['conv2d_288[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_288 (Activation  (None, None, None, 128)      0         ['batch_normalization_288[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_289 (Conv2D)         (None, None, None, 160)      143360    ['activation_288[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_289 (B  (None, None, None, 160)      480       ['conv2d_289[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_289 (Activation  (None, None, None, 160)      0         ['batch_normalization_289[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_287 (Conv2D)         (None, None, None, 192)      208896    ['block17_2_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_290 (Conv2D)         (None, None, None, 192)      215040    ['activation_289[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_287 (B  (None, None, None, 192)      576       ['conv2d_287[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_290 (B  (None, None, None, 192)      576       ['conv2d_290[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_287 (Activation  (None, None, None, 192)      0         ['batch_normalization_287[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_290 (Activation  (None, None, None, 192)      0         ['batch_normalization_290[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block17_3_mixed (Concatena  (None, None, None, 384)      0         ['activation_287[0][0]',      \n",
            " te)                                                                 'activation_290[0][0]']      \n",
            "                                                                                                  \n",
            " block17_3_conv (Conv2D)     (None, None, None, 1088)     418880    ['block17_3_mixed[0][0]']     \n",
            "                                                                                                  \n",
            " custom_scale_layer_52 (Cus  (None, None, None, 1088)     0         ['block17_2_ac[0][0]',        \n",
            " tomScaleLayer)                                                      'block17_3_conv[0][0]']      \n",
            "                                                                                                  \n",
            " block17_3_ac (Activation)   (None, None, None, 1088)     0         ['custom_scale_layer_52[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_292 (Conv2D)         (None, None, None, 128)      139264    ['block17_3_ac[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_292 (B  (None, None, None, 128)      384       ['conv2d_292[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_292 (Activation  (None, None, None, 128)      0         ['batch_normalization_292[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_293 (Conv2D)         (None, None, None, 160)      143360    ['activation_292[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_293 (B  (None, None, None, 160)      480       ['conv2d_293[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_293 (Activation  (None, None, None, 160)      0         ['batch_normalization_293[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_291 (Conv2D)         (None, None, None, 192)      208896    ['block17_3_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_294 (Conv2D)         (None, None, None, 192)      215040    ['activation_293[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_291 (B  (None, None, None, 192)      576       ['conv2d_291[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_294 (B  (None, None, None, 192)      576       ['conv2d_294[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_291 (Activation  (None, None, None, 192)      0         ['batch_normalization_291[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_294 (Activation  (None, None, None, 192)      0         ['batch_normalization_294[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block17_4_mixed (Concatena  (None, None, None, 384)      0         ['activation_291[0][0]',      \n",
            " te)                                                                 'activation_294[0][0]']      \n",
            "                                                                                                  \n",
            " block17_4_conv (Conv2D)     (None, None, None, 1088)     418880    ['block17_4_mixed[0][0]']     \n",
            "                                                                                                  \n",
            " custom_scale_layer_53 (Cus  (None, None, None, 1088)     0         ['block17_3_ac[0][0]',        \n",
            " tomScaleLayer)                                                      'block17_4_conv[0][0]']      \n",
            "                                                                                                  \n",
            " block17_4_ac (Activation)   (None, None, None, 1088)     0         ['custom_scale_layer_53[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_296 (Conv2D)         (None, None, None, 128)      139264    ['block17_4_ac[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_296 (B  (None, None, None, 128)      384       ['conv2d_296[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_296 (Activation  (None, None, None, 128)      0         ['batch_normalization_296[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_297 (Conv2D)         (None, None, None, 160)      143360    ['activation_296[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_297 (B  (None, None, None, 160)      480       ['conv2d_297[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_297 (Activation  (None, None, None, 160)      0         ['batch_normalization_297[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_295 (Conv2D)         (None, None, None, 192)      208896    ['block17_4_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_298 (Conv2D)         (None, None, None, 192)      215040    ['activation_297[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_295 (B  (None, None, None, 192)      576       ['conv2d_295[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_298 (B  (None, None, None, 192)      576       ['conv2d_298[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_295 (Activation  (None, None, None, 192)      0         ['batch_normalization_295[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_298 (Activation  (None, None, None, 192)      0         ['batch_normalization_298[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block17_5_mixed (Concatena  (None, None, None, 384)      0         ['activation_295[0][0]',      \n",
            " te)                                                                 'activation_298[0][0]']      \n",
            "                                                                                                  \n",
            " block17_5_conv (Conv2D)     (None, None, None, 1088)     418880    ['block17_5_mixed[0][0]']     \n",
            "                                                                                                  \n",
            " custom_scale_layer_54 (Cus  (None, None, None, 1088)     0         ['block17_4_ac[0][0]',        \n",
            " tomScaleLayer)                                                      'block17_5_conv[0][0]']      \n",
            "                                                                                                  \n",
            " block17_5_ac (Activation)   (None, None, None, 1088)     0         ['custom_scale_layer_54[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_300 (Conv2D)         (None, None, None, 128)      139264    ['block17_5_ac[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_300 (B  (None, None, None, 128)      384       ['conv2d_300[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_300 (Activation  (None, None, None, 128)      0         ['batch_normalization_300[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_301 (Conv2D)         (None, None, None, 160)      143360    ['activation_300[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_301 (B  (None, None, None, 160)      480       ['conv2d_301[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_301 (Activation  (None, None, None, 160)      0         ['batch_normalization_301[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_299 (Conv2D)         (None, None, None, 192)      208896    ['block17_5_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_302 (Conv2D)         (None, None, None, 192)      215040    ['activation_301[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_299 (B  (None, None, None, 192)      576       ['conv2d_299[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_302 (B  (None, None, None, 192)      576       ['conv2d_302[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_299 (Activation  (None, None, None, 192)      0         ['batch_normalization_299[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_302 (Activation  (None, None, None, 192)      0         ['batch_normalization_302[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block17_6_mixed (Concatena  (None, None, None, 384)      0         ['activation_299[0][0]',      \n",
            " te)                                                                 'activation_302[0][0]']      \n",
            "                                                                                                  \n",
            " block17_6_conv (Conv2D)     (None, None, None, 1088)     418880    ['block17_6_mixed[0][0]']     \n",
            "                                                                                                  \n",
            " custom_scale_layer_55 (Cus  (None, None, None, 1088)     0         ['block17_5_ac[0][0]',        \n",
            " tomScaleLayer)                                                      'block17_6_conv[0][0]']      \n",
            "                                                                                                  \n",
            " block17_6_ac (Activation)   (None, None, None, 1088)     0         ['custom_scale_layer_55[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_304 (Conv2D)         (None, None, None, 128)      139264    ['block17_6_ac[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_304 (B  (None, None, None, 128)      384       ['conv2d_304[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_304 (Activation  (None, None, None, 128)      0         ['batch_normalization_304[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_305 (Conv2D)         (None, None, None, 160)      143360    ['activation_304[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_305 (B  (None, None, None, 160)      480       ['conv2d_305[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_305 (Activation  (None, None, None, 160)      0         ['batch_normalization_305[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_303 (Conv2D)         (None, None, None, 192)      208896    ['block17_6_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_306 (Conv2D)         (None, None, None, 192)      215040    ['activation_305[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_303 (B  (None, None, None, 192)      576       ['conv2d_303[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_306 (B  (None, None, None, 192)      576       ['conv2d_306[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_303 (Activation  (None, None, None, 192)      0         ['batch_normalization_303[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_306 (Activation  (None, None, None, 192)      0         ['batch_normalization_306[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block17_7_mixed (Concatena  (None, None, None, 384)      0         ['activation_303[0][0]',      \n",
            " te)                                                                 'activation_306[0][0]']      \n",
            "                                                                                                  \n",
            " block17_7_conv (Conv2D)     (None, None, None, 1088)     418880    ['block17_7_mixed[0][0]']     \n",
            "                                                                                                  \n",
            " custom_scale_layer_56 (Cus  (None, None, None, 1088)     0         ['block17_6_ac[0][0]',        \n",
            " tomScaleLayer)                                                      'block17_7_conv[0][0]']      \n",
            "                                                                                                  \n",
            " block17_7_ac (Activation)   (None, None, None, 1088)     0         ['custom_scale_layer_56[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_308 (Conv2D)         (None, None, None, 128)      139264    ['block17_7_ac[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_308 (B  (None, None, None, 128)      384       ['conv2d_308[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_308 (Activation  (None, None, None, 128)      0         ['batch_normalization_308[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_309 (Conv2D)         (None, None, None, 160)      143360    ['activation_308[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_309 (B  (None, None, None, 160)      480       ['conv2d_309[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_309 (Activation  (None, None, None, 160)      0         ['batch_normalization_309[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_307 (Conv2D)         (None, None, None, 192)      208896    ['block17_7_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_310 (Conv2D)         (None, None, None, 192)      215040    ['activation_309[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_307 (B  (None, None, None, 192)      576       ['conv2d_307[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_310 (B  (None, None, None, 192)      576       ['conv2d_310[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_307 (Activation  (None, None, None, 192)      0         ['batch_normalization_307[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_310 (Activation  (None, None, None, 192)      0         ['batch_normalization_310[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block17_8_mixed (Concatena  (None, None, None, 384)      0         ['activation_307[0][0]',      \n",
            " te)                                                                 'activation_310[0][0]']      \n",
            "                                                                                                  \n",
            " block17_8_conv (Conv2D)     (None, None, None, 1088)     418880    ['block17_8_mixed[0][0]']     \n",
            "                                                                                                  \n",
            " custom_scale_layer_57 (Cus  (None, None, None, 1088)     0         ['block17_7_ac[0][0]',        \n",
            " tomScaleLayer)                                                      'block17_8_conv[0][0]']      \n",
            "                                                                                                  \n",
            " block17_8_ac (Activation)   (None, None, None, 1088)     0         ['custom_scale_layer_57[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_312 (Conv2D)         (None, None, None, 128)      139264    ['block17_8_ac[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_312 (B  (None, None, None, 128)      384       ['conv2d_312[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_312 (Activation  (None, None, None, 128)      0         ['batch_normalization_312[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_313 (Conv2D)         (None, None, None, 160)      143360    ['activation_312[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_313 (B  (None, None, None, 160)      480       ['conv2d_313[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_313 (Activation  (None, None, None, 160)      0         ['batch_normalization_313[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_311 (Conv2D)         (None, None, None, 192)      208896    ['block17_8_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_314 (Conv2D)         (None, None, None, 192)      215040    ['activation_313[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_311 (B  (None, None, None, 192)      576       ['conv2d_311[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_314 (B  (None, None, None, 192)      576       ['conv2d_314[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_311 (Activation  (None, None, None, 192)      0         ['batch_normalization_311[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_314 (Activation  (None, None, None, 192)      0         ['batch_normalization_314[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block17_9_mixed (Concatena  (None, None, None, 384)      0         ['activation_311[0][0]',      \n",
            " te)                                                                 'activation_314[0][0]']      \n",
            "                                                                                                  \n",
            " block17_9_conv (Conv2D)     (None, None, None, 1088)     418880    ['block17_9_mixed[0][0]']     \n",
            "                                                                                                  \n",
            " custom_scale_layer_58 (Cus  (None, None, None, 1088)     0         ['block17_8_ac[0][0]',        \n",
            " tomScaleLayer)                                                      'block17_9_conv[0][0]']      \n",
            "                                                                                                  \n",
            " block17_9_ac (Activation)   (None, None, None, 1088)     0         ['custom_scale_layer_58[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_316 (Conv2D)         (None, None, None, 128)      139264    ['block17_9_ac[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_316 (B  (None, None, None, 128)      384       ['conv2d_316[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_316 (Activation  (None, None, None, 128)      0         ['batch_normalization_316[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_317 (Conv2D)         (None, None, None, 160)      143360    ['activation_316[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_317 (B  (None, None, None, 160)      480       ['conv2d_317[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_317 (Activation  (None, None, None, 160)      0         ['batch_normalization_317[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_315 (Conv2D)         (None, None, None, 192)      208896    ['block17_9_ac[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_318 (Conv2D)         (None, None, None, 192)      215040    ['activation_317[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_315 (B  (None, None, None, 192)      576       ['conv2d_315[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_318 (B  (None, None, None, 192)      576       ['conv2d_318[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_315 (Activation  (None, None, None, 192)      0         ['batch_normalization_315[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_318 (Activation  (None, None, None, 192)      0         ['batch_normalization_318[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block17_10_mixed (Concaten  (None, None, None, 384)      0         ['activation_315[0][0]',      \n",
            " ate)                                                                'activation_318[0][0]']      \n",
            "                                                                                                  \n",
            " block17_10_conv (Conv2D)    (None, None, None, 1088)     418880    ['block17_10_mixed[0][0]']    \n",
            "                                                                                                  \n",
            " custom_scale_layer_59 (Cus  (None, None, None, 1088)     0         ['block17_9_ac[0][0]',        \n",
            " tomScaleLayer)                                                      'block17_10_conv[0][0]']     \n",
            "                                                                                                  \n",
            " block17_10_ac (Activation)  (None, None, None, 1088)     0         ['custom_scale_layer_59[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_320 (Conv2D)         (None, None, None, 128)      139264    ['block17_10_ac[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_320 (B  (None, None, None, 128)      384       ['conv2d_320[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_320 (Activation  (None, None, None, 128)      0         ['batch_normalization_320[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_321 (Conv2D)         (None, None, None, 160)      143360    ['activation_320[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_321 (B  (None, None, None, 160)      480       ['conv2d_321[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_321 (Activation  (None, None, None, 160)      0         ['batch_normalization_321[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_319 (Conv2D)         (None, None, None, 192)      208896    ['block17_10_ac[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_322 (Conv2D)         (None, None, None, 192)      215040    ['activation_321[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_319 (B  (None, None, None, 192)      576       ['conv2d_319[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_322 (B  (None, None, None, 192)      576       ['conv2d_322[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_319 (Activation  (None, None, None, 192)      0         ['batch_normalization_319[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_322 (Activation  (None, None, None, 192)      0         ['batch_normalization_322[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block17_11_mixed (Concaten  (None, None, None, 384)      0         ['activation_319[0][0]',      \n",
            " ate)                                                                'activation_322[0][0]']      \n",
            "                                                                                                  \n",
            " block17_11_conv (Conv2D)    (None, None, None, 1088)     418880    ['block17_11_mixed[0][0]']    \n",
            "                                                                                                  \n",
            " custom_scale_layer_60 (Cus  (None, None, None, 1088)     0         ['block17_10_ac[0][0]',       \n",
            " tomScaleLayer)                                                      'block17_11_conv[0][0]']     \n",
            "                                                                                                  \n",
            " block17_11_ac (Activation)  (None, None, None, 1088)     0         ['custom_scale_layer_60[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_324 (Conv2D)         (None, None, None, 128)      139264    ['block17_11_ac[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_324 (B  (None, None, None, 128)      384       ['conv2d_324[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_324 (Activation  (None, None, None, 128)      0         ['batch_normalization_324[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_325 (Conv2D)         (None, None, None, 160)      143360    ['activation_324[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_325 (B  (None, None, None, 160)      480       ['conv2d_325[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_325 (Activation  (None, None, None, 160)      0         ['batch_normalization_325[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_323 (Conv2D)         (None, None, None, 192)      208896    ['block17_11_ac[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_326 (Conv2D)         (None, None, None, 192)      215040    ['activation_325[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_323 (B  (None, None, None, 192)      576       ['conv2d_323[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_326 (B  (None, None, None, 192)      576       ['conv2d_326[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_323 (Activation  (None, None, None, 192)      0         ['batch_normalization_323[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_326 (Activation  (None, None, None, 192)      0         ['batch_normalization_326[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block17_12_mixed (Concaten  (None, None, None, 384)      0         ['activation_323[0][0]',      \n",
            " ate)                                                                'activation_326[0][0]']      \n",
            "                                                                                                  \n",
            " block17_12_conv (Conv2D)    (None, None, None, 1088)     418880    ['block17_12_mixed[0][0]']    \n",
            "                                                                                                  \n",
            " custom_scale_layer_61 (Cus  (None, None, None, 1088)     0         ['block17_11_ac[0][0]',       \n",
            " tomScaleLayer)                                                      'block17_12_conv[0][0]']     \n",
            "                                                                                                  \n",
            " block17_12_ac (Activation)  (None, None, None, 1088)     0         ['custom_scale_layer_61[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_328 (Conv2D)         (None, None, None, 128)      139264    ['block17_12_ac[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_328 (B  (None, None, None, 128)      384       ['conv2d_328[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_328 (Activation  (None, None, None, 128)      0         ['batch_normalization_328[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_329 (Conv2D)         (None, None, None, 160)      143360    ['activation_328[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_329 (B  (None, None, None, 160)      480       ['conv2d_329[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_329 (Activation  (None, None, None, 160)      0         ['batch_normalization_329[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_327 (Conv2D)         (None, None, None, 192)      208896    ['block17_12_ac[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_330 (Conv2D)         (None, None, None, 192)      215040    ['activation_329[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_327 (B  (None, None, None, 192)      576       ['conv2d_327[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_330 (B  (None, None, None, 192)      576       ['conv2d_330[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_327 (Activation  (None, None, None, 192)      0         ['batch_normalization_327[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_330 (Activation  (None, None, None, 192)      0         ['batch_normalization_330[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block17_13_mixed (Concaten  (None, None, None, 384)      0         ['activation_327[0][0]',      \n",
            " ate)                                                                'activation_330[0][0]']      \n",
            "                                                                                                  \n",
            " block17_13_conv (Conv2D)    (None, None, None, 1088)     418880    ['block17_13_mixed[0][0]']    \n",
            "                                                                                                  \n",
            " custom_scale_layer_62 (Cus  (None, None, None, 1088)     0         ['block17_12_ac[0][0]',       \n",
            " tomScaleLayer)                                                      'block17_13_conv[0][0]']     \n",
            "                                                                                                  \n",
            " block17_13_ac (Activation)  (None, None, None, 1088)     0         ['custom_scale_layer_62[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_332 (Conv2D)         (None, None, None, 128)      139264    ['block17_13_ac[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_332 (B  (None, None, None, 128)      384       ['conv2d_332[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_332 (Activation  (None, None, None, 128)      0         ['batch_normalization_332[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_333 (Conv2D)         (None, None, None, 160)      143360    ['activation_332[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_333 (B  (None, None, None, 160)      480       ['conv2d_333[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_333 (Activation  (None, None, None, 160)      0         ['batch_normalization_333[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_331 (Conv2D)         (None, None, None, 192)      208896    ['block17_13_ac[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_334 (Conv2D)         (None, None, None, 192)      215040    ['activation_333[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_331 (B  (None, None, None, 192)      576       ['conv2d_331[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_334 (B  (None, None, None, 192)      576       ['conv2d_334[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_331 (Activation  (None, None, None, 192)      0         ['batch_normalization_331[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_334 (Activation  (None, None, None, 192)      0         ['batch_normalization_334[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block17_14_mixed (Concaten  (None, None, None, 384)      0         ['activation_331[0][0]',      \n",
            " ate)                                                                'activation_334[0][0]']      \n",
            "                                                                                                  \n",
            " block17_14_conv (Conv2D)    (None, None, None, 1088)     418880    ['block17_14_mixed[0][0]']    \n",
            "                                                                                                  \n",
            " custom_scale_layer_63 (Cus  (None, None, None, 1088)     0         ['block17_13_ac[0][0]',       \n",
            " tomScaleLayer)                                                      'block17_14_conv[0][0]']     \n",
            "                                                                                                  \n",
            " block17_14_ac (Activation)  (None, None, None, 1088)     0         ['custom_scale_layer_63[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_336 (Conv2D)         (None, None, None, 128)      139264    ['block17_14_ac[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_336 (B  (None, None, None, 128)      384       ['conv2d_336[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_336 (Activation  (None, None, None, 128)      0         ['batch_normalization_336[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_337 (Conv2D)         (None, None, None, 160)      143360    ['activation_336[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_337 (B  (None, None, None, 160)      480       ['conv2d_337[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_337 (Activation  (None, None, None, 160)      0         ['batch_normalization_337[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_335 (Conv2D)         (None, None, None, 192)      208896    ['block17_14_ac[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_338 (Conv2D)         (None, None, None, 192)      215040    ['activation_337[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_335 (B  (None, None, None, 192)      576       ['conv2d_335[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_338 (B  (None, None, None, 192)      576       ['conv2d_338[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_335 (Activation  (None, None, None, 192)      0         ['batch_normalization_335[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_338 (Activation  (None, None, None, 192)      0         ['batch_normalization_338[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block17_15_mixed (Concaten  (None, None, None, 384)      0         ['activation_335[0][0]',      \n",
            " ate)                                                                'activation_338[0][0]']      \n",
            "                                                                                                  \n",
            " block17_15_conv (Conv2D)    (None, None, None, 1088)     418880    ['block17_15_mixed[0][0]']    \n",
            "                                                                                                  \n",
            " custom_scale_layer_64 (Cus  (None, None, None, 1088)     0         ['block17_14_ac[0][0]',       \n",
            " tomScaleLayer)                                                      'block17_15_conv[0][0]']     \n",
            "                                                                                                  \n",
            " block17_15_ac (Activation)  (None, None, None, 1088)     0         ['custom_scale_layer_64[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_340 (Conv2D)         (None, None, None, 128)      139264    ['block17_15_ac[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_340 (B  (None, None, None, 128)      384       ['conv2d_340[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_340 (Activation  (None, None, None, 128)      0         ['batch_normalization_340[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_341 (Conv2D)         (None, None, None, 160)      143360    ['activation_340[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_341 (B  (None, None, None, 160)      480       ['conv2d_341[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_341 (Activation  (None, None, None, 160)      0         ['batch_normalization_341[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_339 (Conv2D)         (None, None, None, 192)      208896    ['block17_15_ac[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_342 (Conv2D)         (None, None, None, 192)      215040    ['activation_341[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_339 (B  (None, None, None, 192)      576       ['conv2d_339[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_342 (B  (None, None, None, 192)      576       ['conv2d_342[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_339 (Activation  (None, None, None, 192)      0         ['batch_normalization_339[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_342 (Activation  (None, None, None, 192)      0         ['batch_normalization_342[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block17_16_mixed (Concaten  (None, None, None, 384)      0         ['activation_339[0][0]',      \n",
            " ate)                                                                'activation_342[0][0]']      \n",
            "                                                                                                  \n",
            " block17_16_conv (Conv2D)    (None, None, None, 1088)     418880    ['block17_16_mixed[0][0]']    \n",
            "                                                                                                  \n",
            " custom_scale_layer_65 (Cus  (None, None, None, 1088)     0         ['block17_15_ac[0][0]',       \n",
            " tomScaleLayer)                                                      'block17_16_conv[0][0]']     \n",
            "                                                                                                  \n",
            " block17_16_ac (Activation)  (None, None, None, 1088)     0         ['custom_scale_layer_65[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_344 (Conv2D)         (None, None, None, 128)      139264    ['block17_16_ac[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_344 (B  (None, None, None, 128)      384       ['conv2d_344[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_344 (Activation  (None, None, None, 128)      0         ['batch_normalization_344[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_345 (Conv2D)         (None, None, None, 160)      143360    ['activation_344[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_345 (B  (None, None, None, 160)      480       ['conv2d_345[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_345 (Activation  (None, None, None, 160)      0         ['batch_normalization_345[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_343 (Conv2D)         (None, None, None, 192)      208896    ['block17_16_ac[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_346 (Conv2D)         (None, None, None, 192)      215040    ['activation_345[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_343 (B  (None, None, None, 192)      576       ['conv2d_343[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_346 (B  (None, None, None, 192)      576       ['conv2d_346[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_343 (Activation  (None, None, None, 192)      0         ['batch_normalization_343[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_346 (Activation  (None, None, None, 192)      0         ['batch_normalization_346[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block17_17_mixed (Concaten  (None, None, None, 384)      0         ['activation_343[0][0]',      \n",
            " ate)                                                                'activation_346[0][0]']      \n",
            "                                                                                                  \n",
            " block17_17_conv (Conv2D)    (None, None, None, 1088)     418880    ['block17_17_mixed[0][0]']    \n",
            "                                                                                                  \n",
            " custom_scale_layer_66 (Cus  (None, None, None, 1088)     0         ['block17_16_ac[0][0]',       \n",
            " tomScaleLayer)                                                      'block17_17_conv[0][0]']     \n",
            "                                                                                                  \n",
            " block17_17_ac (Activation)  (None, None, None, 1088)     0         ['custom_scale_layer_66[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_348 (Conv2D)         (None, None, None, 128)      139264    ['block17_17_ac[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_348 (B  (None, None, None, 128)      384       ['conv2d_348[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_348 (Activation  (None, None, None, 128)      0         ['batch_normalization_348[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_349 (Conv2D)         (None, None, None, 160)      143360    ['activation_348[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_349 (B  (None, None, None, 160)      480       ['conv2d_349[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_349 (Activation  (None, None, None, 160)      0         ['batch_normalization_349[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_347 (Conv2D)         (None, None, None, 192)      208896    ['block17_17_ac[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_350 (Conv2D)         (None, None, None, 192)      215040    ['activation_349[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_347 (B  (None, None, None, 192)      576       ['conv2d_347[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_350 (B  (None, None, None, 192)      576       ['conv2d_350[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_347 (Activation  (None, None, None, 192)      0         ['batch_normalization_347[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_350 (Activation  (None, None, None, 192)      0         ['batch_normalization_350[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block17_18_mixed (Concaten  (None, None, None, 384)      0         ['activation_347[0][0]',      \n",
            " ate)                                                                'activation_350[0][0]']      \n",
            "                                                                                                  \n",
            " block17_18_conv (Conv2D)    (None, None, None, 1088)     418880    ['block17_18_mixed[0][0]']    \n",
            "                                                                                                  \n",
            " custom_scale_layer_67 (Cus  (None, None, None, 1088)     0         ['block17_17_ac[0][0]',       \n",
            " tomScaleLayer)                                                      'block17_18_conv[0][0]']     \n",
            "                                                                                                  \n",
            " block17_18_ac (Activation)  (None, None, None, 1088)     0         ['custom_scale_layer_67[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_352 (Conv2D)         (None, None, None, 128)      139264    ['block17_18_ac[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_352 (B  (None, None, None, 128)      384       ['conv2d_352[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_352 (Activation  (None, None, None, 128)      0         ['batch_normalization_352[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_353 (Conv2D)         (None, None, None, 160)      143360    ['activation_352[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_353 (B  (None, None, None, 160)      480       ['conv2d_353[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_353 (Activation  (None, None, None, 160)      0         ['batch_normalization_353[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_351 (Conv2D)         (None, None, None, 192)      208896    ['block17_18_ac[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_354 (Conv2D)         (None, None, None, 192)      215040    ['activation_353[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_351 (B  (None, None, None, 192)      576       ['conv2d_351[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_354 (B  (None, None, None, 192)      576       ['conv2d_354[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_351 (Activation  (None, None, None, 192)      0         ['batch_normalization_351[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_354 (Activation  (None, None, None, 192)      0         ['batch_normalization_354[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block17_19_mixed (Concaten  (None, None, None, 384)      0         ['activation_351[0][0]',      \n",
            " ate)                                                                'activation_354[0][0]']      \n",
            "                                                                                                  \n",
            " block17_19_conv (Conv2D)    (None, None, None, 1088)     418880    ['block17_19_mixed[0][0]']    \n",
            "                                                                                                  \n",
            " custom_scale_layer_68 (Cus  (None, None, None, 1088)     0         ['block17_18_ac[0][0]',       \n",
            " tomScaleLayer)                                                      'block17_19_conv[0][0]']     \n",
            "                                                                                                  \n",
            " block17_19_ac (Activation)  (None, None, None, 1088)     0         ['custom_scale_layer_68[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_356 (Conv2D)         (None, None, None, 128)      139264    ['block17_19_ac[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_356 (B  (None, None, None, 128)      384       ['conv2d_356[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_356 (Activation  (None, None, None, 128)      0         ['batch_normalization_356[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_357 (Conv2D)         (None, None, None, 160)      143360    ['activation_356[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_357 (B  (None, None, None, 160)      480       ['conv2d_357[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_357 (Activation  (None, None, None, 160)      0         ['batch_normalization_357[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_355 (Conv2D)         (None, None, None, 192)      208896    ['block17_19_ac[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_358 (Conv2D)         (None, None, None, 192)      215040    ['activation_357[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_355 (B  (None, None, None, 192)      576       ['conv2d_355[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_358 (B  (None, None, None, 192)      576       ['conv2d_358[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_355 (Activation  (None, None, None, 192)      0         ['batch_normalization_355[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_358 (Activation  (None, None, None, 192)      0         ['batch_normalization_358[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block17_20_mixed (Concaten  (None, None, None, 384)      0         ['activation_355[0][0]',      \n",
            " ate)                                                                'activation_358[0][0]']      \n",
            "                                                                                                  \n",
            " block17_20_conv (Conv2D)    (None, None, None, 1088)     418880    ['block17_20_mixed[0][0]']    \n",
            "                                                                                                  \n",
            " custom_scale_layer_69 (Cus  (None, None, None, 1088)     0         ['block17_19_ac[0][0]',       \n",
            " tomScaleLayer)                                                      'block17_20_conv[0][0]']     \n",
            "                                                                                                  \n",
            " block17_20_ac (Activation)  (None, None, None, 1088)     0         ['custom_scale_layer_69[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_363 (Conv2D)         (None, None, None, 256)      278528    ['block17_20_ac[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_363 (B  (None, None, None, 256)      768       ['conv2d_363[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_363 (Activation  (None, None, None, 256)      0         ['batch_normalization_363[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_359 (Conv2D)         (None, None, None, 256)      278528    ['block17_20_ac[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_361 (Conv2D)         (None, None, None, 256)      278528    ['block17_20_ac[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_364 (Conv2D)         (None, None, None, 288)      663552    ['activation_363[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_359 (B  (None, None, None, 256)      768       ['conv2d_359[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_361 (B  (None, None, None, 256)      768       ['conv2d_361[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_364 (B  (None, None, None, 288)      864       ['conv2d_364[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_359 (Activation  (None, None, None, 256)      0         ['batch_normalization_359[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_361 (Activation  (None, None, None, 256)      0         ['batch_normalization_361[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_364 (Activation  (None, None, None, 288)      0         ['batch_normalization_364[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_360 (Conv2D)         (None, None, None, 384)      884736    ['activation_359[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_362 (Conv2D)         (None, None, None, 288)      663552    ['activation_361[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_365 (Conv2D)         (None, None, None, 320)      829440    ['activation_364[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_360 (B  (None, None, None, 384)      1152      ['conv2d_360[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_362 (B  (None, None, None, 288)      864       ['conv2d_362[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_365 (B  (None, None, None, 320)      960       ['conv2d_365[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_360 (Activation  (None, None, None, 384)      0         ['batch_normalization_360[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_362 (Activation  (None, None, None, 288)      0         ['batch_normalization_362[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_365 (Activation  (None, None, None, 320)      0         ['batch_normalization_365[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPoolin  (None, None, None, 1088)     0         ['block17_20_ac[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " mixed_7a (Concatenate)      (None, None, None, 2080)     0         ['activation_360[0][0]',      \n",
            "                                                                     'activation_362[0][0]',      \n",
            "                                                                     'activation_365[0][0]',      \n",
            "                                                                     'max_pooling2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_367 (Conv2D)         (None, None, None, 192)      399360    ['mixed_7a[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_367 (B  (None, None, None, 192)      576       ['conv2d_367[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_367 (Activation  (None, None, None, 192)      0         ['batch_normalization_367[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_368 (Conv2D)         (None, None, None, 224)      129024    ['activation_367[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_368 (B  (None, None, None, 224)      672       ['conv2d_368[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_368 (Activation  (None, None, None, 224)      0         ['batch_normalization_368[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_366 (Conv2D)         (None, None, None, 192)      399360    ['mixed_7a[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_369 (Conv2D)         (None, None, None, 256)      172032    ['activation_368[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_366 (B  (None, None, None, 192)      576       ['conv2d_366[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_369 (B  (None, None, None, 256)      768       ['conv2d_369[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_366 (Activation  (None, None, None, 192)      0         ['batch_normalization_366[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_369 (Activation  (None, None, None, 256)      0         ['batch_normalization_369[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block8_1_mixed (Concatenat  (None, None, None, 448)      0         ['activation_366[0][0]',      \n",
            " e)                                                                  'activation_369[0][0]']      \n",
            "                                                                                                  \n",
            " block8_1_conv (Conv2D)      (None, None, None, 2080)     933920    ['block8_1_mixed[0][0]']      \n",
            "                                                                                                  \n",
            " custom_scale_layer_70 (Cus  (None, None, None, 2080)     0         ['mixed_7a[0][0]',            \n",
            " tomScaleLayer)                                                      'block8_1_conv[0][0]']       \n",
            "                                                                                                  \n",
            " block8_1_ac (Activation)    (None, None, None, 2080)     0         ['custom_scale_layer_70[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_371 (Conv2D)         (None, None, None, 192)      399360    ['block8_1_ac[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_371 (B  (None, None, None, 192)      576       ['conv2d_371[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_371 (Activation  (None, None, None, 192)      0         ['batch_normalization_371[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_372 (Conv2D)         (None, None, None, 224)      129024    ['activation_371[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_372 (B  (None, None, None, 224)      672       ['conv2d_372[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_372 (Activation  (None, None, None, 224)      0         ['batch_normalization_372[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_370 (Conv2D)         (None, None, None, 192)      399360    ['block8_1_ac[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_373 (Conv2D)         (None, None, None, 256)      172032    ['activation_372[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_370 (B  (None, None, None, 192)      576       ['conv2d_370[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_373 (B  (None, None, None, 256)      768       ['conv2d_373[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_370 (Activation  (None, None, None, 192)      0         ['batch_normalization_370[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_373 (Activation  (None, None, None, 256)      0         ['batch_normalization_373[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block8_2_mixed (Concatenat  (None, None, None, 448)      0         ['activation_370[0][0]',      \n",
            " e)                                                                  'activation_373[0][0]']      \n",
            "                                                                                                  \n",
            " block8_2_conv (Conv2D)      (None, None, None, 2080)     933920    ['block8_2_mixed[0][0]']      \n",
            "                                                                                                  \n",
            " custom_scale_layer_71 (Cus  (None, None, None, 2080)     0         ['block8_1_ac[0][0]',         \n",
            " tomScaleLayer)                                                      'block8_2_conv[0][0]']       \n",
            "                                                                                                  \n",
            " block8_2_ac (Activation)    (None, None, None, 2080)     0         ['custom_scale_layer_71[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_375 (Conv2D)         (None, None, None, 192)      399360    ['block8_2_ac[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_375 (B  (None, None, None, 192)      576       ['conv2d_375[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_375 (Activation  (None, None, None, 192)      0         ['batch_normalization_375[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_376 (Conv2D)         (None, None, None, 224)      129024    ['activation_375[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_376 (B  (None, None, None, 224)      672       ['conv2d_376[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_376 (Activation  (None, None, None, 224)      0         ['batch_normalization_376[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_374 (Conv2D)         (None, None, None, 192)      399360    ['block8_2_ac[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_377 (Conv2D)         (None, None, None, 256)      172032    ['activation_376[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_374 (B  (None, None, None, 192)      576       ['conv2d_374[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_377 (B  (None, None, None, 256)      768       ['conv2d_377[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_374 (Activation  (None, None, None, 192)      0         ['batch_normalization_374[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_377 (Activation  (None, None, None, 256)      0         ['batch_normalization_377[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block8_3_mixed (Concatenat  (None, None, None, 448)      0         ['activation_374[0][0]',      \n",
            " e)                                                                  'activation_377[0][0]']      \n",
            "                                                                                                  \n",
            " block8_3_conv (Conv2D)      (None, None, None, 2080)     933920    ['block8_3_mixed[0][0]']      \n",
            "                                                                                                  \n",
            " custom_scale_layer_72 (Cus  (None, None, None, 2080)     0         ['block8_2_ac[0][0]',         \n",
            " tomScaleLayer)                                                      'block8_3_conv[0][0]']       \n",
            "                                                                                                  \n",
            " block8_3_ac (Activation)    (None, None, None, 2080)     0         ['custom_scale_layer_72[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_379 (Conv2D)         (None, None, None, 192)      399360    ['block8_3_ac[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_379 (B  (None, None, None, 192)      576       ['conv2d_379[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_379 (Activation  (None, None, None, 192)      0         ['batch_normalization_379[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_380 (Conv2D)         (None, None, None, 224)      129024    ['activation_379[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_380 (B  (None, None, None, 224)      672       ['conv2d_380[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_380 (Activation  (None, None, None, 224)      0         ['batch_normalization_380[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_378 (Conv2D)         (None, None, None, 192)      399360    ['block8_3_ac[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_381 (Conv2D)         (None, None, None, 256)      172032    ['activation_380[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_378 (B  (None, None, None, 192)      576       ['conv2d_378[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_381 (B  (None, None, None, 256)      768       ['conv2d_381[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_378 (Activation  (None, None, None, 192)      0         ['batch_normalization_378[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_381 (Activation  (None, None, None, 256)      0         ['batch_normalization_381[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block8_4_mixed (Concatenat  (None, None, None, 448)      0         ['activation_378[0][0]',      \n",
            " e)                                                                  'activation_381[0][0]']      \n",
            "                                                                                                  \n",
            " block8_4_conv (Conv2D)      (None, None, None, 2080)     933920    ['block8_4_mixed[0][0]']      \n",
            "                                                                                                  \n",
            " custom_scale_layer_73 (Cus  (None, None, None, 2080)     0         ['block8_3_ac[0][0]',         \n",
            " tomScaleLayer)                                                      'block8_4_conv[0][0]']       \n",
            "                                                                                                  \n",
            " block8_4_ac (Activation)    (None, None, None, 2080)     0         ['custom_scale_layer_73[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_383 (Conv2D)         (None, None, None, 192)      399360    ['block8_4_ac[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_383 (B  (None, None, None, 192)      576       ['conv2d_383[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_383 (Activation  (None, None, None, 192)      0         ['batch_normalization_383[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_384 (Conv2D)         (None, None, None, 224)      129024    ['activation_383[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_384 (B  (None, None, None, 224)      672       ['conv2d_384[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_384 (Activation  (None, None, None, 224)      0         ['batch_normalization_384[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_382 (Conv2D)         (None, None, None, 192)      399360    ['block8_4_ac[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_385 (Conv2D)         (None, None, None, 256)      172032    ['activation_384[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_382 (B  (None, None, None, 192)      576       ['conv2d_382[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_385 (B  (None, None, None, 256)      768       ['conv2d_385[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_382 (Activation  (None, None, None, 192)      0         ['batch_normalization_382[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_385 (Activation  (None, None, None, 256)      0         ['batch_normalization_385[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block8_5_mixed (Concatenat  (None, None, None, 448)      0         ['activation_382[0][0]',      \n",
            " e)                                                                  'activation_385[0][0]']      \n",
            "                                                                                                  \n",
            " block8_5_conv (Conv2D)      (None, None, None, 2080)     933920    ['block8_5_mixed[0][0]']      \n",
            "                                                                                                  \n",
            " custom_scale_layer_74 (Cus  (None, None, None, 2080)     0         ['block8_4_ac[0][0]',         \n",
            " tomScaleLayer)                                                      'block8_5_conv[0][0]']       \n",
            "                                                                                                  \n",
            " block8_5_ac (Activation)    (None, None, None, 2080)     0         ['custom_scale_layer_74[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_387 (Conv2D)         (None, None, None, 192)      399360    ['block8_5_ac[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_387 (B  (None, None, None, 192)      576       ['conv2d_387[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_387 (Activation  (None, None, None, 192)      0         ['batch_normalization_387[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_388 (Conv2D)         (None, None, None, 224)      129024    ['activation_387[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_388 (B  (None, None, None, 224)      672       ['conv2d_388[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_388 (Activation  (None, None, None, 224)      0         ['batch_normalization_388[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_386 (Conv2D)         (None, None, None, 192)      399360    ['block8_5_ac[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_389 (Conv2D)         (None, None, None, 256)      172032    ['activation_388[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_386 (B  (None, None, None, 192)      576       ['conv2d_386[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_389 (B  (None, None, None, 256)      768       ['conv2d_389[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_386 (Activation  (None, None, None, 192)      0         ['batch_normalization_386[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_389 (Activation  (None, None, None, 256)      0         ['batch_normalization_389[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block8_6_mixed (Concatenat  (None, None, None, 448)      0         ['activation_386[0][0]',      \n",
            " e)                                                                  'activation_389[0][0]']      \n",
            "                                                                                                  \n",
            " block8_6_conv (Conv2D)      (None, None, None, 2080)     933920    ['block8_6_mixed[0][0]']      \n",
            "                                                                                                  \n",
            " custom_scale_layer_75 (Cus  (None, None, None, 2080)     0         ['block8_5_ac[0][0]',         \n",
            " tomScaleLayer)                                                      'block8_6_conv[0][0]']       \n",
            "                                                                                                  \n",
            " block8_6_ac (Activation)    (None, None, None, 2080)     0         ['custom_scale_layer_75[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_391 (Conv2D)         (None, None, None, 192)      399360    ['block8_6_ac[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_391 (B  (None, None, None, 192)      576       ['conv2d_391[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_391 (Activation  (None, None, None, 192)      0         ['batch_normalization_391[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_392 (Conv2D)         (None, None, None, 224)      129024    ['activation_391[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_392 (B  (None, None, None, 224)      672       ['conv2d_392[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_392 (Activation  (None, None, None, 224)      0         ['batch_normalization_392[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_390 (Conv2D)         (None, None, None, 192)      399360    ['block8_6_ac[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_393 (Conv2D)         (None, None, None, 256)      172032    ['activation_392[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_390 (B  (None, None, None, 192)      576       ['conv2d_390[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_393 (B  (None, None, None, 256)      768       ['conv2d_393[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_390 (Activation  (None, None, None, 192)      0         ['batch_normalization_390[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_393 (Activation  (None, None, None, 256)      0         ['batch_normalization_393[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block8_7_mixed (Concatenat  (None, None, None, 448)      0         ['activation_390[0][0]',      \n",
            " e)                                                                  'activation_393[0][0]']      \n",
            "                                                                                                  \n",
            " block8_7_conv (Conv2D)      (None, None, None, 2080)     933920    ['block8_7_mixed[0][0]']      \n",
            "                                                                                                  \n",
            " custom_scale_layer_76 (Cus  (None, None, None, 2080)     0         ['block8_6_ac[0][0]',         \n",
            " tomScaleLayer)                                                      'block8_7_conv[0][0]']       \n",
            "                                                                                                  \n",
            " block8_7_ac (Activation)    (None, None, None, 2080)     0         ['custom_scale_layer_76[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_395 (Conv2D)         (None, None, None, 192)      399360    ['block8_7_ac[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_395 (B  (None, None, None, 192)      576       ['conv2d_395[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_395 (Activation  (None, None, None, 192)      0         ['batch_normalization_395[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_396 (Conv2D)         (None, None, None, 224)      129024    ['activation_395[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_396 (B  (None, None, None, 224)      672       ['conv2d_396[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_396 (Activation  (None, None, None, 224)      0         ['batch_normalization_396[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_394 (Conv2D)         (None, None, None, 192)      399360    ['block8_7_ac[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_397 (Conv2D)         (None, None, None, 256)      172032    ['activation_396[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_394 (B  (None, None, None, 192)      576       ['conv2d_394[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_397 (B  (None, None, None, 256)      768       ['conv2d_397[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_394 (Activation  (None, None, None, 192)      0         ['batch_normalization_394[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_397 (Activation  (None, None, None, 256)      0         ['batch_normalization_397[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block8_8_mixed (Concatenat  (None, None, None, 448)      0         ['activation_394[0][0]',      \n",
            " e)                                                                  'activation_397[0][0]']      \n",
            "                                                                                                  \n",
            " block8_8_conv (Conv2D)      (None, None, None, 2080)     933920    ['block8_8_mixed[0][0]']      \n",
            "                                                                                                  \n",
            " custom_scale_layer_77 (Cus  (None, None, None, 2080)     0         ['block8_7_ac[0][0]',         \n",
            " tomScaleLayer)                                                      'block8_8_conv[0][0]']       \n",
            "                                                                                                  \n",
            " block8_8_ac (Activation)    (None, None, None, 2080)     0         ['custom_scale_layer_77[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_399 (Conv2D)         (None, None, None, 192)      399360    ['block8_8_ac[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_399 (B  (None, None, None, 192)      576       ['conv2d_399[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_399 (Activation  (None, None, None, 192)      0         ['batch_normalization_399[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_400 (Conv2D)         (None, None, None, 224)      129024    ['activation_399[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_400 (B  (None, None, None, 224)      672       ['conv2d_400[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_400 (Activation  (None, None, None, 224)      0         ['batch_normalization_400[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_398 (Conv2D)         (None, None, None, 192)      399360    ['block8_8_ac[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_401 (Conv2D)         (None, None, None, 256)      172032    ['activation_400[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_398 (B  (None, None, None, 192)      576       ['conv2d_398[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_401 (B  (None, None, None, 256)      768       ['conv2d_401[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_398 (Activation  (None, None, None, 192)      0         ['batch_normalization_398[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_401 (Activation  (None, None, None, 256)      0         ['batch_normalization_401[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block8_9_mixed (Concatenat  (None, None, None, 448)      0         ['activation_398[0][0]',      \n",
            " e)                                                                  'activation_401[0][0]']      \n",
            "                                                                                                  \n",
            " block8_9_conv (Conv2D)      (None, None, None, 2080)     933920    ['block8_9_mixed[0][0]']      \n",
            "                                                                                                  \n",
            " custom_scale_layer_78 (Cus  (None, None, None, 2080)     0         ['block8_8_ac[0][0]',         \n",
            " tomScaleLayer)                                                      'block8_9_conv[0][0]']       \n",
            "                                                                                                  \n",
            " block8_9_ac (Activation)    (None, None, None, 2080)     0         ['custom_scale_layer_78[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_403 (Conv2D)         (None, None, None, 192)      399360    ['block8_9_ac[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_403 (B  (None, None, None, 192)      576       ['conv2d_403[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_403 (Activation  (None, None, None, 192)      0         ['batch_normalization_403[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_404 (Conv2D)         (None, None, None, 224)      129024    ['activation_403[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_404 (B  (None, None, None, 224)      672       ['conv2d_404[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_404 (Activation  (None, None, None, 224)      0         ['batch_normalization_404[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_402 (Conv2D)         (None, None, None, 192)      399360    ['block8_9_ac[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_405 (Conv2D)         (None, None, None, 256)      172032    ['activation_404[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_402 (B  (None, None, None, 192)      576       ['conv2d_402[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_405 (B  (None, None, None, 256)      768       ['conv2d_405[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_402 (Activation  (None, None, None, 192)      0         ['batch_normalization_402[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_405 (Activation  (None, None, None, 256)      0         ['batch_normalization_405[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " block8_10_mixed (Concatena  (None, None, None, 448)      0         ['activation_402[0][0]',      \n",
            " te)                                                                 'activation_405[0][0]']      \n",
            "                                                                                                  \n",
            " block8_10_conv (Conv2D)     (None, None, None, 2080)     933920    ['block8_10_mixed[0][0]']     \n",
            "                                                                                                  \n",
            " custom_scale_layer_79 (Cus  (None, None, None, 2080)     0         ['block8_9_ac[0][0]',         \n",
            " tomScaleLayer)                                                      'block8_10_conv[0][0]']      \n",
            "                                                                                                  \n",
            " conv_7b (Conv2D)            (None, None, None, 1536)     3194880   ['custom_scale_layer_79[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv_7b_bn (BatchNormaliza  (None, None, None, 1536)     4608      ['conv_7b[0][0]']             \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " conv_7b_ac (Activation)     (None, None, None, 1536)     0         ['conv_7b_bn[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 54336736 (207.28 MB)\n",
            "Trainable params: 54276192 (207.05 MB)\n",
            "Non-trainable params: 60544 (236.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Check if GPU is available\n",
        "if tf.config.experimental.list_physical_devices('GPU'):\n",
        "    print('GPU is available. Using CUDA.')\n",
        "else:\n",
        "    print('GPU is not available. Using CPU.')\n",
        "\n",
        "# Load the pre-trained Inception-ResNet V2 model without the top layers\n",
        "base_model = tf.keras.applications.InceptionResNetV2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Modify the model to suit the number of classes in the CUB dataset\n",
        "num_classes = 200  # CUB dataset has 200 classes\n",
        "\n",
        "# Add custom classification head\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(1024, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# Load CUB dataset\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/CUB-200-2011-dataset/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    '/content/CUB-200-2011-dataset/test',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=len(validation_generator)\n",
        ")\n",
        "\n",
        "# Optionally, you can fine-tune the entire model by unfreezing the base model layers and recompiling the model.\n",
        "# base_model.trainable = True\n",
        "# model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "#               loss='categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "# history = model.fit(...)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0SdDwYJDbuc1",
        "outputId": "b17bb9c5-2582-4989-f479-2cc038cc5515"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available. Using CUDA.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inception_resnet_v2 (Funct  (None, 5, 5, 1536)        54336736  \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " global_average_pooling2d_1  (None, 1536)              0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1024)              1573888   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 200)               205000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 56115624 (214.06 MB)\n",
            "Trainable params: 1778888 (6.79 MB)\n",
            "Non-trainable params: 54336736 (207.28 MB)\n",
            "_________________________________________________________________\n",
            "Found 5994 images belonging to 200 classes.\n",
            "Found 5794 images belonging to 200 classes.\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 143s 668ms/step - loss: 4.3677 - accuracy: 0.0966 - val_loss: 3.2394 - val_accuracy: 0.2104\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 127s 675ms/step - loss: 3.3682 - accuracy: 0.1890 - val_loss: 2.8015 - val_accuracy: 0.2829\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 124s 661ms/step - loss: 3.0306 - accuracy: 0.2321 - val_loss: 2.6133 - val_accuracy: 0.3152\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 122s 650ms/step - loss: 2.8093 - accuracy: 0.2684 - val_loss: 2.4566 - val_accuracy: 0.3471\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 130s 694ms/step - loss: 2.6670 - accuracy: 0.2906 - val_loss: 2.3838 - val_accuracy: 0.3614\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 122s 646ms/step - loss: 2.5456 - accuracy: 0.3150 - val_loss: 2.3298 - val_accuracy: 0.3683\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 121s 642ms/step - loss: 2.4532 - accuracy: 0.3277 - val_loss: 2.2377 - val_accuracy: 0.3940\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 121s 645ms/step - loss: 2.3507 - accuracy: 0.3477 - val_loss: 2.1984 - val_accuracy: 0.3945\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - ETA: 0s - loss: 2.2839 - accuracy: 0.3680"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-98f17d406da1>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1854\u001b[0m                             \u001b[0mpss_evaluation_shards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pss_evaluation_shards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m                         )\n\u001b[0;32m-> 1856\u001b[0;31m                     val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1857\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2294\u001b[0m                         ):\n\u001b[1;32m   2295\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2296\u001b[0;31m                             logs = test_function_runner.run_step(\n\u001b[0m\u001b[1;32m   2297\u001b[0m                                 \u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2298\u001b[0m                                 \u001b[0mdata_handler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   4106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_shards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m         \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    878\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Load the pre-trained Inception model and freeze its layers\n",
        "inception_model = models.inception_v3(pretrained=True)\n",
        "for param in inception_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the inception model's output to match the number of classes in CUB dataset\n",
        "inception_model.fc = nn.Linear(inception_model.fc.in_features, 200)\n",
        "\n",
        "# Load the pre-trained ResNet-18 model\n",
        "resnet_model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Modify the ResNet-18 model's output to match the number of classes in CUB dataset\n",
        "resnet_model.fc = nn.Linear(resnet_model.fc.in_features, 200)\n",
        "\n",
        "train_dir = '/content/CUB-200-2011-dataset/train'\n",
        "val_dir = '/content/CUB-200-2011-dataset/test'\n",
        "\n",
        "# Define transformations for data augmentation and normalization\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Load the CUB dataset\n",
        "# Load the CUB dataset\n",
        "image_datasets = {x: datasets.ImageFolder(root=train_dir if x == 'train' else val_dir, transform=data_transforms[x]) for x in ['train', 'val']}\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=2) for x in ['train', 'val']}\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(resnet_model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the ResNet-18 model\n",
        "resnet_model.to(device)\n",
        "resnet_model.train()\n",
        "for epoch in range(10):  # Adjust the number of epochs as needed\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in dataloaders['train']:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = resnet_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "    epoch_loss = running_loss / len(dataloaders['train'].dataset)\n",
        "    print(f\"Epoch {epoch+1}/{10}, Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "# Optionally, evaluate the model on the validation set\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNKoPY8jxm_3",
        "outputId": "9cd09dca-b74f-44f6-c091-4324a03c8d2f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|| 97.8M/97.8M [00:00<00:00, 167MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 5.3700\n",
            "Epoch 2/10, Loss: 5.0362\n",
            "Epoch 3/10, Loss: 4.7875\n",
            "Epoch 4/10, Loss: 4.5910\n",
            "Epoch 5/10, Loss: 4.4562\n",
            "Epoch 6/10, Loss: 4.2665\n",
            "Epoch 7/10, Loss: 4.1266\n",
            "Epoch 8/10, Loss: 3.9432\n",
            "Epoch 9/10, Loss: 3.8123\n",
            "Epoch 10/10, Loss: 3.6841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "resnet_model.eval()  # Set model to evaluation mode\n",
        "with torch.no_grad():  # Disable gradient computation\n",
        "    for images, labels in dataloaders['val']:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = resnet_model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy on the validation set: {100 * correct / total:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu1QLaRQ33FJ",
        "outputId": "65824e79-c414-4a61-87d4-c32b3b21b3bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the validation set: 16.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 2 VGG"
      ],
      "metadata": {
        "id": "JjZsGw-b8Tte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Load the pre-trained VGG16 model and freeze its layers\n",
        "vgg_model = models.vgg16(pretrained=True)\n",
        "for param in vgg_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the VGG16 model's output to match the number of classes in CUB dataset\n",
        "num_classes = 200  # Number of classes in CUB dataset\n",
        "vgg_model.classifier[-1] = nn.Linear(vgg_model.classifier[-1].in_features, num_classes)\n",
        "\n",
        "train_dir = '/content/CUB-200-2011-dataset/train'\n",
        "val_dir = '/content/CUB-200-2011-dataset/test'\n",
        "\n",
        "# Define transformations for data augmentation and normalization\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Load the CUB dataset\n",
        "image_datasets = {x: datasets.ImageFolder(root=train_dir if x == 'train' else val_dir, transform=data_transforms[x]) for x in ['train', 'val']}\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=2) for x in ['train', 'val']}\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(vgg_model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the VGG16 model\n",
        "vgg_model.to(device)\n",
        "vgg_model.train()\n",
        "for epoch in range(10):  # Adjust the number of epochs as needed\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in dataloaders['train']:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = vgg_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "    epoch_loss = running_loss / len(dataloaders['train'].dataset)\n",
        "    print(f\"Epoch {epoch+1}/{10}, Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "# Optionally, evaluate the model on the validation set\n",
        "correct = 0\n",
        "total = 0\n",
        "vgg_model.eval()  # Set model to evaluation mode\n",
        "with torch.no_grad():  # Disable gradient computation\n",
        "    for images, labels in dataloaders['val']:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = vgg_model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy on the validation set: {100 * correct / total:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZNAEtL-8XDz",
        "outputId": "259fc760-291f-41fd-993d-c462b33b589d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|| 528M/528M [00:07<00:00, 75.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 3.4894\n",
            "Epoch 2/10, Loss: 2.3955\n",
            "Epoch 3/10, Loss: 2.1588\n",
            "Epoch 4/10, Loss: 2.1331\n",
            "Epoch 5/10, Loss: 2.0151\n",
            "Epoch 6/10, Loss: 1.9804\n",
            "Epoch 7/10, Loss: 2.0138\n",
            "Epoch 8/10, Loss: 1.9433\n",
            "Epoch 9/10, Loss: 1.9762\n",
            "Epoch 10/10, Loss: 1.9616\n",
            "Accuracy on the validation set: 59.48%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of total parameters in the model\n",
        "total_params = sum(p.numel() for p in vgg_model.parameters())\n",
        "print(f'Total parameters in the model: {total_params}')\n",
        "\n",
        "# Calculate the number of trainable parameters in the model\n",
        "trainable_params = sum(p.numel() for p in vgg_model.parameters() if p.requires_grad)\n",
        "print(f'Total trainable parameters in the model: {trainable_params}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qYyTBya-UNE",
        "outputId": "201f7c42-47ad-4e8e-bead-09b7a413dfdb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters in the model: 135079944\n",
            "Total trainable parameters in the model: 819400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 3\n",
        "FineTuning on Unfreezing Some layers"
      ],
      "metadata": {
        "id": "BFYZ51WZ_jLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_dir = '/content/CUB-200-2011-dataset/train'\n",
        "val_dir = '/content/CUB-200-2011-dataset/test'\n",
        "\n",
        "# Define transformations for data augmentation and normalization\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Load the CUB dataset\n",
        "image_datasets = {x: datasets.ImageFolder(root=train_dir if x == 'train' else val_dir, transform=data_transforms[x]) for x in ['train', 'val']}\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=2) for x in ['train', 'val']}\n",
        "\n",
        "# Load pre-trained VGG16\n",
        "vgg16 = models.vgg16(pretrained=True)\n",
        "\n",
        "# Freeze all layers\n",
        "for param in vgg16.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze some convolutional layers\n",
        "for i in range(10):\n",
        "    for param in vgg16.features[-i].parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "# Modify the classifier\n",
        "num_features = vgg16.classifier[6].in_features\n",
        "vgg16.classifier[6] = nn.Linear(num_features, 200)\n",
        "\n",
        "# Move model to device\n",
        "vgg16 = vgg16.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    vgg16.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for images, labels in dataloaders['train']:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = vgg16(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloaders['train'].dataset)\n",
        "    train_accuracy = correct_train / total_train\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Train Accuracy: {train_accuracy:.2%}\")\n",
        "\n",
        "    # Evaluation loop\n",
        "    vgg16.eval()\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    val_running_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloaders['val']:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = vgg16(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "            val_loss = criterion(outputs, labels)\n",
        "            val_running_loss += val_loss.item() * images.size(0)\n",
        "\n",
        "    val_epoch_loss = val_running_loss / len(dataloaders['val'].dataset)\n",
        "    val_accuracy = correct_val / total_val\n",
        "\n",
        "    print(f\"Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.2%}\")\n",
        "\n",
        "# Print final test accuracy\n",
        "print(f\"Final Test Accuracy: {val_accuracy:.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyWV-Sr0_iAR",
        "outputId": "bc67c31a-314f-452a-82cd-ac8dbabaaf41"
      },
      "execution_count": 19,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 4.4325\n",
            "Epoch [2/20], Loss: 2.7754\n",
            "Epoch [3/20], Loss: 2.2339\n",
            "Epoch [4/20], Loss: 1.9940\n",
            "Epoch [5/20], Loss: 1.7927\n",
            "Epoch [6/20], Loss: 1.6844\n",
            "Epoch [7/20], Loss: 1.5739\n",
            "Epoch [8/20], Loss: 1.4961\n",
            "Epoch [9/20], Loss: 1.4105\n",
            "Epoch [10/20], Loss: 1.3621\n",
            "Epoch [11/20], Loss: 1.3106\n",
            "Epoch [12/20], Loss: 1.2844\n",
            "Epoch [13/20], Loss: 1.2286\n",
            "Epoch [14/20], Loss: 1.2040\n",
            "Epoch [15/20], Loss: 1.1629\n",
            "Epoch [16/20], Loss: 1.0885\n",
            "Epoch [17/20], Loss: 1.0909\n",
            "Epoch [18/20], Loss: 1.0458\n",
            "Epoch [19/20], Loss: 0.9779\n",
            "Epoch [20/20], Loss: 0.9909\n",
            "Accuracy on validation set: 72.51%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of total parameters in the model\n",
        "total_params = sum(p.numel() for p in vgg16.parameters())\n",
        "print(f'Total parameters in the model: {total_params}')\n",
        "\n",
        "# Calculate the number of trainable parameters in the model\n",
        "trainable_params = sum(p.numel() for p in vgg16.parameters() if p.requires_grad)\n",
        "print(f'Total trainable parameters in the model: {trainable_params}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrjC_FFBHHqo",
        "outputId": "a2ad5789-7dff-4092-af9d-07cc580a551c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters in the model: 135079944\n",
            "Total trainable parameters in the model: 7900616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 4"
      ],
      "metadata": {
        "id": "eXyJehFxNFmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_dir = '/content/CUB-200-2011-dataset/train'\n",
        "val_dir = '/content/CUB-200-2011-dataset/test'\n",
        "\n",
        "# Define transformations for data augmentation and normalization\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Load the CUB dataset\n",
        "image_datasets = {x: datasets.ImageFolder(root=train_dir if x == 'train' else val_dir, transform=data_transforms[x]) for x in ['train', 'val']}\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=2) for x in ['train', 'val']}\n",
        "\n",
        "# Load pre-trained VGG16\n",
        "vgg16 = models.vgg16(pretrained=True)\n",
        "\n",
        "# Freeze all layers\n",
        "for param in vgg16.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze some convolutional layers\n",
        "for i, param in enumerate(vgg16.features.parameters(), 1):\n",
        "    if i > 15:  # Adjust the number of layers to unfreeze as needed\n",
        "        param.requires_grad = True\n",
        "\n",
        "# Modify the classifier\n",
        "num_features = vgg16.classifier[6].in_features\n",
        "vgg16.classifier[6] = nn.Linear(num_features, 200)  # Set to 200 for CUB dataset\n",
        "\n",
        "\n",
        "# Move model to device\n",
        "vgg16 = vgg16.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 25\n",
        "for epoch in range(num_epochs):\n",
        "    vgg16.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for images, labels in dataloaders['train']:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = vgg16(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloaders['train'].dataset)\n",
        "    train_accuracy = correct_train / total_train\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Train Accuracy: {train_accuracy:.2%}\")\n",
        "\n",
        "    # Evaluation loop\n",
        "    vgg16.eval()\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    val_running_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloaders['val']:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = vgg16(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "            val_loss = criterion(outputs, labels)\n",
        "            val_running_loss += val_loss.item() * images.size(0)\n",
        "\n",
        "    val_epoch_loss = val_running_loss / len(dataloaders['val'].dataset)\n",
        "    val_accuracy = correct_val / total_val\n",
        "\n",
        "    print(f\"Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.2%}\")\n",
        "\n",
        "# Print final test accuracy\n",
        "print(f\"Final Test Accuracy: {val_accuracy:.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2XLnJYUND9w",
        "outputId": "32c8289e-c5ee-4e32-8e9f-7ebbd7fb660c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/25], Train Loss: 4.3873, Train Accuracy: 10.33%\n",
            "Validation Loss: 2.4603, Validation Accuracy: 37.50%\n",
            "Epoch [2/25], Train Loss: 2.6973, Train Accuracy: 33.12%\n",
            "Validation Loss: 1.6088, Validation Accuracy: 55.83%\n",
            "Epoch [3/25], Train Loss: 2.1916, Train Accuracy: 43.88%\n",
            "Validation Loss: 1.4274, Validation Accuracy: 59.42%\n",
            "Epoch [4/25], Train Loss: 1.8801, Train Accuracy: 51.13%\n",
            "Validation Loss: 1.2382, Validation Accuracy: 65.50%\n",
            "Epoch [5/25], Train Loss: 1.7157, Train Accuracy: 53.85%\n",
            "Validation Loss: 1.1386, Validation Accuracy: 68.45%\n",
            "Epoch [6/25], Train Loss: 1.5927, Train Accuracy: 57.66%\n",
            "Validation Loss: 1.1649, Validation Accuracy: 67.26%\n",
            "Epoch [7/25], Train Loss: 1.4792, Train Accuracy: 60.68%\n",
            "Validation Loss: 1.0694, Validation Accuracy: 70.11%\n",
            "Epoch [8/25], Train Loss: 1.4144, Train Accuracy: 62.88%\n",
            "Validation Loss: 1.0397, Validation Accuracy: 70.95%\n",
            "Epoch [9/25], Train Loss: 1.3412, Train Accuracy: 64.30%\n",
            "Validation Loss: 1.0389, Validation Accuracy: 70.62%\n",
            "Epoch [10/25], Train Loss: 1.2708, Train Accuracy: 66.17%\n",
            "Validation Loss: 1.0149, Validation Accuracy: 72.52%\n",
            "Epoch [11/25], Train Loss: 1.2355, Train Accuracy: 67.43%\n",
            "Validation Loss: 1.0322, Validation Accuracy: 72.49%\n",
            "Epoch [12/25], Train Loss: 1.1350, Train Accuracy: 68.95%\n",
            "Validation Loss: 0.9959, Validation Accuracy: 72.95%\n",
            "Epoch [13/25], Train Loss: 1.1468, Train Accuracy: 68.54%\n",
            "Validation Loss: 1.0021, Validation Accuracy: 72.56%\n",
            "Epoch [14/25], Train Loss: 1.0584, Train Accuracy: 71.35%\n",
            "Validation Loss: 0.9812, Validation Accuracy: 72.76%\n",
            "Epoch [15/25], Train Loss: 1.0268, Train Accuracy: 71.97%\n",
            "Validation Loss: 0.9988, Validation Accuracy: 72.95%\n",
            "Epoch [16/25], Train Loss: 1.0118, Train Accuracy: 72.44%\n",
            "Validation Loss: 0.9746, Validation Accuracy: 73.85%\n",
            "Epoch [17/25], Train Loss: 0.9728, Train Accuracy: 73.66%\n",
            "Validation Loss: 0.9988, Validation Accuracy: 73.68%\n",
            "Epoch [18/25], Train Loss: 0.9291, Train Accuracy: 74.16%\n",
            "Validation Loss: 1.0482, Validation Accuracy: 73.06%\n",
            "Epoch [19/25], Train Loss: 0.9328, Train Accuracy: 74.89%\n",
            "Validation Loss: 0.9513, Validation Accuracy: 75.06%\n",
            "Epoch [20/25], Train Loss: 0.8871, Train Accuracy: 76.63%\n",
            "Validation Loss: 0.9677, Validation Accuracy: 74.54%\n",
            "Epoch [21/25], Train Loss: 0.8636, Train Accuracy: 76.64%\n",
            "Validation Loss: 1.0194, Validation Accuracy: 74.04%\n",
            "Epoch [22/25], Train Loss: 0.8462, Train Accuracy: 77.23%\n",
            "Validation Loss: 0.9851, Validation Accuracy: 74.73%\n",
            "Epoch [23/25], Train Loss: 0.8624, Train Accuracy: 76.74%\n",
            "Validation Loss: 0.9873, Validation Accuracy: 75.16%\n",
            "Epoch [24/25], Train Loss: 0.8344, Train Accuracy: 77.66%\n",
            "Validation Loss: 0.9863, Validation Accuracy: 74.54%\n",
            "Epoch [25/25], Train Loss: 0.8253, Train Accuracy: 77.51%\n",
            "Validation Loss: 1.0012, Validation Accuracy: 75.44%\n",
            "Final Test Accuracy: 75.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 5\n",
        "FineTuning the Layers of VGG 19"
      ],
      "metadata": {
        "id": "C7vE5CzBUuhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "train_dir = '/content/CUB-200-2011-dataset/train'\n",
        "val_dir = '/content/CUB-200-2011-dataset/test'\n",
        "\n",
        "# Define transformations for data augmentation and normalization\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Load the CUB dataset\n",
        "image_datasets = {x: datasets.ImageFolder(root=train_dir if x == 'train' else val_dir, transform=data_transforms[x]) for x in ['train', 'val']}\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=2) for x in ['train', 'val']}\n",
        "\n",
        "# Load pre-trained VGG19\n",
        "vgg19 = models.vgg19(weights='DEFAULT')\n",
        "\n",
        "# Freeze all layers\n",
        "for param in vgg19.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze some convolutional layers\n",
        "for i, param in enumerate(vgg19.features.parameters(), 1):\n",
        "    if i > 20:  # Adjust the number of layers to unfreeze as needed\n",
        "        param.requires_grad = True\n",
        "\n",
        "# Modify the classifier\n",
        "num_features = vgg19.classifier[6].in_features\n",
        "vgg19.classifier[6] = nn.Linear(num_features, 200)  # Set to 200 for CUB dataset\n",
        "\n",
        "# Move model to device\n",
        "vgg19 = vgg19.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(vgg19.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 25\n",
        "for epoch in range(num_epochs):\n",
        "    vgg19.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for images, labels in dataloaders['train']:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = vgg19(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloaders['train'].dataset)\n",
        "    train_accuracy = correct_train / total_train\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Train Accuracy: {train_accuracy:.2%}\")\n",
        "\n",
        "    # Evaluation loop\n",
        "    vgg19.eval()\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    val_running_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloaders['val']:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = vgg19(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "            val_loss = criterion(outputs, labels)\n",
        "            val_running_loss += val_loss.item() * images.size(0)\n",
        "\n",
        "    val_epoch_loss = val_running_loss / len(dataloaders['val'].dataset)\n",
        "    val_accuracy = correct_val / total_val\n",
        "\n",
        "    print(f\"Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.2%}\")\n",
        "\n",
        "# Print final test accuracy\n",
        "print(f\"Final Test Accuracy: {val_accuracy:.2%}\")\n"
      ],
      "metadata": {
        "id": "eedCERAZUidk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 6\n",
        "Efficient Net"
      ],
      "metadata": {
        "id": "JVLZO7srXPWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7rpUedaXN8N",
        "outputId": "52a39e42-6035-4d44-877b-1510a87763f5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet-pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=740faa7ebbcf35b5a07f85fd9c2cb8c634348b03ffbb700d6612ca653577e674\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "train_dir = '/content/CUB-200-2011-dataset/train'\n",
        "val_dir = '/content/CUB-200-2011-dataset/test'\n",
        "\n",
        "# Define transformations for data augmentation and normalization\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Load the CUB dataset\n",
        "image_datasets = {x: datasets.ImageFolder(root=train_dir if x == 'train' else val_dir, transform=data_transforms[x]) for x in ['train', 'val']}\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=2) for x in ['train', 'val']}\n",
        "\n",
        "# Load pre-trained EfficientNet (e.g., EfficientNet-B0)\n",
        "efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "\n",
        "# Modify the classifier\n",
        "num_features = efficientnet._fc.in_features\n",
        "efficientnet._fc = nn.Linear(num_features, 200)  # Set to 200 for CUB dataset\n",
        "\n",
        "# Move model to device\n",
        "efficientnet = efficientnet.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(efficientnet.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 25\n",
        "for epoch in range(num_epochs):\n",
        "    efficientnet.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for images, labels in dataloaders['train']:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = efficientnet(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloaders['train'].dataset)\n",
        "    train_accuracy = correct_train / total_train\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Train Accuracy: {train_accuracy:.2%}\")\n",
        "\n",
        "    # Evaluation loop\n",
        "    efficientnet.eval()\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    val_running_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloaders['val']:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = efficientnet(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "            val_loss = criterion(outputs, labels)\n",
        "            val_running_loss += val_loss.item() * images.size(0)\n",
        "\n",
        "    val_epoch_loss = val_running_loss / len(dataloaders['val'].dataset)\n",
        "    val_accuracy = correct_val / total_val\n",
        "\n",
        "    print(f\"Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.2%}\")\n",
        "\n",
        "# Print final test accuracy\n",
        "print(f\"Final Test Accuracy: {val_accuracy:.2%}\")\n"
      ],
      "metadata": {
        "id": "tzHll10WXX2E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}